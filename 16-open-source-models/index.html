<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Index - genaibeginner</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Index";
        var mkdocs_page_input_path = "16-open-source-models\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../genaibeginner/00-course-setup/translations/cn/README.md">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../09-building-image-applications/translations/cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Index</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <p><a href="https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst"><img alt="Open Source Models" src="images/16-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<h2 id="introduction">Introduction</h2>
<p>The world of open-source LLMs is exciting and constantly evolving. This lesson aims to provide an in-depth look at open source models. If you are looking for information on how proprietary models compare to open source models, go to the <a href="../02-exploring-and-comparing-different-llms/?WT.mc_id=academic-105485-koreyst">"Exploring and Comparing Different LLMs" lesson</a>. This lesson will also cover the topic of fine-tuning but a more detailed explanation can be found in the <a href="../18-fine-tuning/?WT.mc_id=academic-105485-koreyst">"Fine-Tuning LLMs" lesson</a>.</p>
<h2 id="learning-goals">Learning goals</h2>
<ul>
<li>Gain an understanding of open source Models</li>
<li>Understanding the benefits of working with open source Models</li>
<li>Exploring the open models available on Hugging Face and the Azure AI Studio</li>
</ul>
<h2 id="what-are-open-source-models">What are Open Source Models?</h2>
<p>Open source software has played a crucial role in the growth of technology across various fields. The Open Source Initiative (OSI) has defined <a href="https://opensource.org/osd?WT.mc_id=academic-105485-koreyst">10 criteria for software</a> to be classified as open source. The source code must be openly shared under a license approved by the OSI.</p>
<p>While the development of LLMs has similar elements to developing software, the process is not exactly the same. This has brought much discussion in the community on the definition of open source in the context of LLMs. For a model to be aligned with the traditional definition of open source the following information should be publicly available:</p>
<ul>
<li>Datasets used to train the model.</li>
<li>Full model weights as a part of the training.</li>
<li>The evaluation code.</li>
<li>The fine-tuning code.</li>
<li>Full model weights and training metrics.</li>
</ul>
<p>There are currently only a few models that match this criteria. The <a href="https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst">OLMo model created by Allen Institute for Artificial Intelligence (AllenAI)</a> is one that fits this category.</p>
<p>For this lesson, we will refer to the models as "open models" going forward as they may not match the criteria above at the time of writing.</p>
<h2 id="benefits-of-open-models">Benefits of Open Models</h2>
<p><strong>Highly Customizable</strong> - Since open models are released with detailed training information, researchers and developers can modify the model's internals. This enables the creation of highly specialized models that are fine-tuned for a specific task or area of study. Some examples of this are code generation, mathematical operations and biology.</p>
<p><strong>Cost</strong> - The cost per token for using and deploying these models is lower than that of proprietary models. When building Generative AI applications, looking at performance vs price when working with these models on your use case should be done.</p>
<p><img alt="Model Cost" src="images/model-price.png?WT.mc_id=academic-105485-koreyst" />
Source: Artificial Analysis</p>
<p><strong>Flexibility</strong> - Working with open models enables you to be flexible in terms of using different models or combining them. An example of this is the <a href="https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst">HuggingChat Assistants </a> where a user can select the model being used directly in the user interface:</p>
<p><img alt="Choose Model" src="images/choose-model.png?WT.mc_id=academic-105485-koreyst" /></p>
<h2 id="exploring-different-open-models">Exploring Different Open Models</h2>
<h3 id="llama-2">Llama 2</h3>
<p><a href="https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst">LLama2</a>, developed by Meta is an open model that is optimized for chat based applications. This is due to its fine-tuning method, which included a large amount of dialogue and human feedback. With this method, the model produces more results that are aligned to human expectation which provides a better user experience.</p>
<p>Some examples of fine-tuned versions of Llama include <a href="https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst">Japanese Llama</a>, which specializes in Japanese and <a href="https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst">Llama Pro</a>, which is an enhanced version of the base model.</p>
<h3 id="mistral">Mistral</h3>
<p><a href="https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst">Mistral</a> is an open model with a strong focus of high performance and efficiency. It uses the Mixture-of-Experts approach which combines a group of specialized expert models into one system where depending on the input, certain models are selected to be used. This makes the computation more effective as models are only addressing the inputs they are specialized in.</p>
<p>Some examples of fine-tuned versions of Mistral include <a href="https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst">BioMistral</a>, which is focused on the medical domain and <a href="https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst">OpenMath Mistral</a>, which performs mathematical computation.</p>
<h3 id="falcon">Falcon</h3>
<p><a href="https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst">Falcon</a> is an LLM created by the Technology Innovation Institute (<strong>TII</strong>). The Falcon-40B was trained on 40 billion parameters which has been shown to perform better than GPT-3 with less compute budget. This is due to its use of the FlashAttention algorithm and multiquery attention that enables it to cut down on the memory requirements at inference time. With this reduced inference time, the Falcon-40B is suitable for chat applications.</p>
<p>Some examples of fine-tuned versions of Falcon are the <a href="https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst">OpenAssistant</a>, an assistant built on open models and <a href="https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst">GPT4ALL</a>, which delivers higher performance than the base model.</p>
<h2 id="how-to-choose">How to Choose</h2>
<p>There is no one answer for choosing an open model. A good place to start is by using the Azure AI Studio's filter by task feature. This will help you understand what types of tasks the model has been trained for. Hugging Face also maintains an LLM Leaderboard which shows you the best performing models based on certain metrics.</p>
<p>When looking to compare LLMs across the different types, <a href="https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst">Artificial Analysis</a> is another great resource:</p>
<p><img alt="Model Quality" src="images/model-quality.png?WT.mc_id=academic-105485-koreyst" />
Source: Artifical Analysis</p>
<p>If working on a specific use case, searching for fine-tuned versions that are focused on the same area can be effective. Experimenting with multiple open models to see how they perform according to your and your users' expectations is another good practice</p>
<h2 id="next-steps">Next Steps</h2>
<p>The best part about open models is that you can get started working with them pretty quickly. Check out the <a href="https://ai.azure.com?WT.mc_id=academic-105485-koreyst">Azure AI Studio Model Catalog</a>, which features a specific Hugging Face collection with these models we discussed here.</p>
<h2 id="learning-does-not-stop-here-continue-the-journey">Learning does not stop here, continue the Journey</h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
