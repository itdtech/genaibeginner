<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>第二十一章：Meta的模型 - genaibeginner</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u7b2c\u4e8c\u5341\u4e00\u7ae0\uff1aMeta\u7684\u6a21\u578b";
        var mkdocs_page_input_path = "21-meta\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../genaibeginner/00-course-setup/translations/cn/README.md">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../09-building-image-applications/translations/cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">第二十一章：Meta的模型</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#the-meta-family-of-models">The Meta Family of Models</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#llama-31">Llama 3.1</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#native-function-calling">Native Function Calling</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#llama-32">Llama 3.2</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#multimodal-support-with-llama-32">Multimodal Support with Llama 3.2</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#learning-does-not-stop-here-continue-the-journey">Learning does not stop here, continue the Journey</a>
    </li>
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">第二十一章：Meta的模型</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="building-with-the-meta-family-models">Building With the Meta Family Models</h1>
<h2 id="introduction">Introduction</h2>
<p>This lesson will cover: </p>
<ul>
<li>Exploring the two main Meta family models - Llama 3.1 and Llama 3.2 </li>
<li>Understanding the use-cases and scenarios for each model </li>
<li>Code sample to show the unique features of each model </li>
</ul>
<h2 id="the-meta-family-of-models">The Meta Family of Models</h2>
<p>In this lesson, we will explore 2 models from the Meta family or "Llama Herd" - Llama 3.1 and Llama 3.2 </p>
<p>These models come in different variants and are available on the Github Model marketplace. Here are more details on using Github Models to <a href="https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst">prototype with AI models</a>.</p>
<p>Model Variants: 
- Llama 3.1 - 70B Instruct 
- Llama 3.1 - 405B Instruct 
- Llama 3.2 - 11B Vision Instruct 
- Llama 3.2 - 90B Vision Instruct </p>
<p><em>Note: Llama 3 is also available on Github Models but won't be covered in this lesson</em></p>
<h2 id="llama-31">Llama 3.1</h2>
<p>At 405 Billion Parameters, Llama 3.1 fits into the open source LLM category. </p>
<p>The mode is an upgrade to the earlier release Llama 3 by offering: </p>
<ul>
<li>Larger context window - 128k tokens vs 8k tokens </li>
<li>Larger Max Output Tokens - 4096 vs 2048 </li>
<li>Better Multilingual Support - due to increase in training tokens </li>
</ul>
<p>These enables Llama 3.1 to handle more complex use cases  when building GenAI applications including: 
- Native Function Calling - the ability to call external tools and functions outside of the LLM workflow
- Better RAG Performance - due to the higher context window 
- Synthetic Data Generation - the ability to create effective data for tasks such as fine-tuning </p>
<h3 id="native-function-calling">Native Function Calling</h3>
<p>Llama 3.1 has been fine-tuned to be more effective at making function or tool calls. It also has two built-in tools that the model can identify as needing to be used based on the prompt from the user. These tools are: </p>
<ul>
<li><strong>Brave Search</strong> - Can be used to get up-to-date information like the weather by performing a web search </li>
<li><strong>Wolfram Alpha</strong> - Can be used for more complex mathematical calculations so writing your own functions is not required. </li>
</ul>
<p>You can also create your own custom tools that LLM can call. </p>
<p>In the code example below: </p>
<ul>
<li>We define the available tools (brave_search, wolfram_alpha) in the system prompt. </li>
<li>Send a user prompt that asks about the weather in a certain city. </li>
<li>The LLM will respond with a tool call to the Brave Search tool which will look like this <code>&lt;|python_tag|&gt;brave_search.call(query="Stockholm weather")</code> </li>
</ul>
<p>*Note: This example only make the tool call, if you would like to get the results, you will need to create a free account on the Brave API page and define the function itself` </p>
<pre><code class="language-python">import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ[&quot;GITHUB_TOKEN&quot;]
endpoint = &quot;https://models.inference.ai.azure.com&quot;
model_name = &quot;meta-llama-3.1-405b-instruct&quot;

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)


tool_prompt=f&quot;&quot;&quot;
&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;

Environment: ipython
Tools: brave_search, wolfram_alpha
Cutting Knowledge Date: December 2023
Today Date: 23 July 2024

You are a helpful assistant&lt;|eot_id|&gt;
&quot;&quot;&quot;

messages = [
    SystemMessage(content=tool_prompt),
    UserMessage(content=&quot;What is the weather in Stockholm?&quot;),

]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
</code></pre>
<h2 id="llama-32">Llama 3.2</h2>
<p>Despite being a LLM, one limitation that Llama 3.1 has is multimodality. That is, being able to use different types of input such as images as prompts and providing responses. This ability is one of the main features of Llama 3.2. These features also include: </p>
<ul>
<li>Multimodality -  has the ability to evaluate both text and image prompts </li>
<li>Small to Medium size variations (11B and 90B) - this provides flexible deployment options, </li>
<li>Text-only variations (1B and 3B) - this allows the model to be deployed on edge / mobile devices and provides low latency </li>
</ul>
<p>The multimodal support represents a big step in the world of open source models. The code example below takes both an image and text prompt to get an analysis of the image from Llama 3.2 90B. </p>
<h3 id="multimodal-support-with-llama-32">Multimodal Support with Llama 3.2</h3>
<pre><code class="language-python">import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import (
    SystemMessage,
    UserMessage,
    TextContentItem,
    ImageContentItem,
    ImageUrl,
    ImageDetailLevel,
)
from azure.core.credentials import AzureKeyCredential

token = os.environ[&quot;GITHUB_TOKEN&quot;]
endpoint = &quot;https://models.inference.ai.azure.com&quot;
model_name = &quot;Llama-3.2-90B-Vision-Instruct&quot;

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage(
            content=&quot;You are a helpful assistant that describes images in details.&quot;
        ),
        UserMessage(
            content=[
                TextContentItem(text=&quot;What's in this image?&quot;),
                ImageContentItem(
                    image_url=ImageUrl.load(
                        image_file=&quot;sample.jpg&quot;,
                        image_format=&quot;jpg&quot;,
                        detail=ImageDetailLevel.LOW)
                ),
            ],
        ),
    ],
    model=model_name,
)

print(response.choices[0].message.content)
</code></pre>
<h2 id="learning-does-not-stop-here-continue-the-journey">Learning does not stop here, continue the Journey</h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../20-mistral/" class="btn btn-neutral float-left" title="第二十章：Mistral的模型"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../20-mistral/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
