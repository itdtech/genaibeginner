<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Criando aplicativos de geração de imagens - GenAI新手入门</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Criando aplicativos de gera\u00e7\u00e3o de imagens";
        var mkdocs_page_input_path = "09-building-image-applications\\translations\\pt-br\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> GenAI新手入门
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../00-course-setup/translations/cn/">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">GenAI新手入门</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Criando aplicativos de geração de imagens</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="criando-aplicativos-de-geracao-de-imagens">Criando aplicativos de geração de imagens</h1>
<p><a href="https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst"><img alt="Building Image Generation Applications" src="../../images/09-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<p>Ainda há muito mais que os LLMs podem fazer além da geração de texto. Também é possível gerar imagens a partir de descrições de texto. Ter imagens como modalidade pode ser altamente útil em uma série de áreas, desde MedTech, arquitetura, turismo, desenvolvimento de jogos e muito mais. Neste capítulo, veremos os dois modelos de geração de imagens mais populares, DALL-E e Midjourney.</p>
<h2 id="introduction">Introduction</h2>
<p>In this lesson, we will cover:</p>
<ul>
<li>Image generation and why it's useful.</li>
<li>DALL-E and Midjourney, what they are, and how they work.</li>
<li>How you would build an image generation app.</li>
</ul>
<h2 id="learning-goals">Learning Goals</h2>
<p>After completing this lesson, you will be able to:</p>
<ul>
<li>Build an image generation application.</li>
<li>Define boundaries for your application with meta prompts.</li>
<li>Work with DALL-E and Midjourney.</li>
</ul>
<h2 id="why-build-an-image-generation-application">Why build an image generation application?</h2>
<p>Image generation applications are a great way to explore the capabilities of Generative AI. They can be used for, for example:</p>
<ul>
<li>
<p><strong>Image editing and synthesis</strong>. You can generate images for a variety of use cases, such as image editing and image synthesis.</p>
</li>
<li>
<p><strong>Applied to a variety of industries</strong>. They can also be used to generate images for a variety of industries like Medtech, Tourism, Game development and more.</p>
</li>
</ul>
<h2 id="scenario-edu4all">Scenario: Edu4All</h2>
<p>As part of this lesson, we will continue to work with our startup, Edu4All, in this lesson. The students will create images for their assessments, exactly what images is up to the students, but they could be illustrations for their own fairytale or create a new character for their story or help them visualize their ideas and concepts.</p>
<p>Here's what Edu4All's students could generate for example if they're working in class on monuments:</p>
<p><img alt="Edu4All startup, class on monuments, Eiffel Tower" src="../../images/startup.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>using a prompt like</p>
<h2 id="introducao">Introdução</h2>
<p>Nesta lição, abordaremos:</p>
<ul>
<li>Geração de imagens e por que é útil.</li>
<li>DALL-E e Midjourney, o que são e como funcionam.</li>
<li>Como criar uma aplicação de geração de imagens.</li>
</ul>
<h2 id="metas-de-aprendizado">Metas de Aprendizado</h2>
<p>Após completar esta lição, você será capaz de:</p>
<ul>
<li>Criar uma aplicação de geração de imagens.</li>
<li>Definir limites para o seu aplicativo com meta-prompts.</li>
<li>Trabalhar com DALL-E e Midjourney.</li>
</ul>
<h2 id="por-que-criar-um-aplicativo-de-geracao-de-imagens">Por que criar um aplicativo de geração de imagens?</h2>
<p>Aplicativos de geração de imagens são uma ótima maneira de explorar as capacidades da Inteligência Artificial Generativa. Eles podem ser usados, por exemplo:</p>
<ul>
<li>
<p><strong>Edição e síntese de imagens</strong>: Você pode gerar imagens para uma variedade de casos de uso, como edição e síntese de imagens.</p>
</li>
<li>
<p><strong>Aplicados a várias indústrias</strong>: Eles também podem ser usados para gerar imagens para diversas indústrias como: Medtech, Turismo, Desenvolvimento de Jogos e muito mais.</p>
</li>
</ul>
<h2 id="cenario-edu4all">Cenário: Edu4All</h2>
<p>Como parte desta lição, continuaremos a trabalhar com nossa startup, Edu4All. Os estudantes criarão imagens para suas avaliações, exatamente quais imagens ficam a critério dos estudantes, mas podem ser ilustrações para seu próprio conto de fadas, criar um novo personagem para sua história ou ajudá-los a visualizar suas ideias e conceitos.</p>
<p>Veja o que os estudantes da Edu4All poderiam gerar, por exemplo, se estivessem trabalhando em sala de aula sobre monumentos:</p>
<p><img alt="Edu4All startup, aula sobre monumentos, Torre Eiffel" src="../../images/startup.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>usando um prompt como:</p>
<blockquote>
<p>"Dog next to Eiffel Tower in early morning sunlight"</p>
</blockquote>
<h2 id="o-que-e-dall-e-e-midjourney">O que é DALL-E e Midjourney?</h2>
<p><a href="https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst">DALL-E</a> e <a href="https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst">Midjourney</a> são dois dos modelos de geração de imagens mais populares, eles permitem que você use prompts para gerar imagens.</p>
<h3 id="dall-e">DALL-E</h3>
<p>Vamos começar com o DALL-E, que é um modelo de Inteligência Artificial Generativa que gera imagens a partir de descrições de texto.</p>
<blockquote>
<p><a href="https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst">DALL-E é uma combinação de dois modelos, CLIP e atenção difusa</a>.</p>
</blockquote>
<ul>
<li>
<p><strong>CLIP</strong> é um modelo que gera embeddings, que são representações numéricas de dados, a partir de imagens e texto.</p>
</li>
<li>
<p><strong>Atenção difusa</strong> é um modelo que gera imagens a partir de embeddings. O DALL-E é treinado em um conjunto de dados de imagens e texto e pode ser usado para gerar imagens a partir de descrições de texto. Por exemplo, o DALL-E pode ser usado para gerar imagens de um gato com chapéu ou um cachorro com um moicano.</p>
</li>
</ul>
<h3 id="midjourney">Midjourney</h3>
<p>Midjourney funciona de maneira semelhante ao DALL-E, gerando imagens a partir de prompts de texto. Midjourney também pode ser usado para gerar imagens usando prompts como "um gato com chapéu" ou "um cachorro com um moicano".</p>
<p><img alt="Imagem gerada pelo Midjourney, pombo mecânico" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst" />
<em>Créditos da imagem: Wikipedia, imagem gerada pelo Midjourney</em></p>
<h2 id="como-dall-e-e-midjourney-funcionam">Como DALL-E e Midjourney Funcionam</h2>
<p>Primeiro, <a href="https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst">DALL-E</a>. DALL-E é um modelo de Inteligência Artificial Generativa baseado na arquitetura do transformer com um <em>transformer autoregressivo</em>.</p>
<p>Um <em>transformer autoregressivo</em> define como um modelo gera imagens a partir de descrições de texto, gerando um pixel de cada vez e, em seguida, usando os pixels gerados para gerar o próximo pixel. Passando por várias camadas em uma rede neural, até que a imagem esteja completa.</p>
<p>Com esse processo, o DALL-E controla atributos, objetos, características e muito mais na imagem que gera. No entanto, DALL-E 2 e 3 têm mais controle sobre a imagem gerada.</p>
<h2 id="criando-seu-primeiro-aplicativo-de-geracao-de-imagens">Criando seu primeiro aplicativo de geração de imagens</h2>
<p>Então, o que é necessário para construir um aplicativo de geração de imagens? Você precisa das seguintes bibliotecas:</p>
<ul>
<li><strong>python-dotenv</strong>, é altamente recomendável usar esta biblioteca para manter suas informações confidenciais em um arquivo <em>.env</em> longe do código.</li>
<li><strong>openai</strong>, esta biblioteca é o que você usará para interagir com a API da OpenAI.</li>
<li><strong>pillow</strong>, para trabalhar com imagens em Python.</li>
<li>
<p><strong>requests</strong>, para ajudar você a fazer solicitações HTTP.</p>
</li>
<li>
<p>Crie um arquivo <em>.env</em> com o seguinte conteúdo:</p>
</li>
</ul>
<p><code>text
   AZURE_OPENAI_ENDPOINT=&lt;your endpoint&gt;
   AZURE_OPENAI_API_KEY=&lt;your key&gt;</code></p>
<p>Encontre essas informações no Portal do Azure para o seu recurso na seção "Chaves e Endpoint".</p>
<ol>
<li>Cole as bibliotecas acima em um arquivo chamado <em>requirements.txt</em> assim:</li>
</ol>
<p><code>text
   python-dotenv
   openai
   pillow
   requests</code></p>
<ol>
<li>Depois, crie um ambiente virtual e instale as bibliotecas:</li>
</ol>
<p><code>bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt</code></p>
<p>Para Windows, use os seguintes comandos para criar e ativar seu ambiente virtual:</p>
<p><code>bash
   python3 -m venv venv
   venv\Scripts\activate.bat</code></p>
<ol>
<li>Adicione o seguinte código em um arquivo chamado <em>app.py</em>:</li>
</ol>
<p>```python
   import openai
   import os
   import requests
   from PIL import Image
   import dotenv</p>
<p># import dotenv
   dotenv.load_dotenv()</p>
<p># Get endpoint and key from environment variables
   openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
   openai.api_key = os.environ['AZURE_OPENAI_API_KEY']</p>
<p># Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)
   openai.api_version = '2023-06-01-preview'
   openai.api_type = 'azure'</p>
<p>try:
       # Create an image by using the image generation API
       generation_response = openai.Image.create(
           prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
           size='1024x1024',
           n=2,
           temperature=0,
       )
       # Set the directory for the stored image
       image_dir = os.path.join(os.curdir, 'images')</p>
<pre><code>   # If the directory doesn't exist, create it
   if not os.path.isdir(image_dir):
       os.mkdir(image_dir)

   # Initialize the image path (note the filetype should be png)
   image_path = os.path.join(image_dir, 'generated-image.png')

   # Retrieve the generated image
   image_url = generation_response["data"][0]["url"]  # extract image URL from response
   generated_image = requests.get(image_url).content  # download the image
   with open(image_path, "wb") as image_file:
       image_file.write(generated_image)

   # Display the image in the default image viewer
   image = Image.open(image_path)
   image.show()
</code></pre>
<p># catch exceptions
   except openai.InvalidRequestError as err:
       print(err)</p>
<p>```</p>
<p>Vamos explicar este código:</p>
<ul>
<li>Primeiro, importamos as bibliotecas de que precisamos, incluindo as bibliotecas OpenAI, dotenv, request e Pillow.</li>
</ul>
<p><code>python
  import openai
  import os
  import requests
  from PIL import Image
  import dotenv</code></p>
<ul>
<li>Depois, carregamos as variáveis de ambiente do arquivo <em>.env</em>.</li>
</ul>
<p><code>python
  # import dotenv
  dotenv.load_dotenv()</code></p>
<ul>
<li>Após isso, definimos o endpoint, a chave para a API OpenAI, a versão e o tipo.</li>
</ul>
<p>```python
  # Get endpoint and key from environment variables
  openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
  openai.api_key = os.environ['AZURE_OPENAI_API_KEY']</p>
<p># add version and type, Azure specific
  openai.api_version = '2023-06-01-preview'
  openai.api_type = 'azure'
  ```</p>
<ul>
<li>Depois, geramos a imagem:</li>
</ul>
<p><code>python
  # Create an image by using the image generation API
  generation_response = openai.Image.create(
      prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
      size='1024x1024',
      n=2,
      temperature=0,
  )</code></p>
<p>Acima está o código que responde com um objeto JSON que contém a URL da imagem gerada. Podemos usar a URL para baixar a imagem e salvá-la em um arquivo.</p>
<ul>
<li>Finalmente, abrimos a imagem e usamos o visualizador de imagens padrão para exibi-la:</li>
</ul>
<p><code>python
  image = Image.open(image_path)
  image.show()</code></p>
<h3 id="mais-detalhes-sobre-a-geracao-da-imagem">Mais detalhes sobre a geração da imagem</h3>
<p>Vamos dar uma olhada no código que gera a imagem com mais detalhes:</p>
<pre><code class="language-python">generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
</code></pre>
<ul>
<li>
<p><strong>prompt</strong> é o prompt de texto usado para gerar a imagem. Neste caso, estamos usando o prompt: "Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils".</p>
</li>
<li>
<p><strong>size</strong> é o tamanho da imagem gerada. Neste caso, estamos gerando uma imagem de 1024x1024 pixels.</p>
</li>
<li>
<p><strong>n</strong> é o número de imagens geradas. Neste caso, estamos gerando duas imagens.</p>
</li>
<li>
<p><strong>temperature</strong> é um parâmetro que controla a aleatoriedade da saída de um modelo de Inteligência Artificial Generativa. A temperatura é um valor entre 0 e 1, onde 0 significa que a saída é determinística e 1 significa que a saída é aleatória. O valor padrão é 0.7.</p>
</li>
</ul>
<p>Há mais coisas que você pode fazer com imagens que abordaremos na próxima seção.</p>
<h2 id="mais-capacidades-de-geracao-de-imagens">Mais capacidades de geração de imagens</h2>
<p>Você viu até agora como conseguimos gerar uma imagem usando algumas linhas em Python. No entanto, há mais coisas que você pode fazer com imagens.</p>
<p>Você também pode fazer o seguinte:</p>
<ul>
<li>
<p><strong>Perform edits</strong>. By providing an existing image a mask and a prompt, you can alter an image. For example, you can add something to a portion of an image. Imagine our bunny image, you can add a hat to the bunny. How you would do that is by providing the image, a mask (identifying the part of the area for the change) and a text prompt to say what should be done.</p>
</li>
<li>
<p><strong>Realizar edições</strong>: Ao fornecer uma imagem existente, uma máscara e um prompt, você pode alterar uma imagem. Por exemplo, você pode adicionar algo a uma parte de uma imagem. Imagine nossa imagem de coelho, você pode adicionar um chapéu ao coelho. Como você faria isso é fornecendo a imagem, uma máscara (identificando a parte da área para a mudança) e um prompt de texto para dizer o que deve ser feito.</p>
</li>
</ul>
<p><code>python
  response = openai.Image.create_edit(
    image=open("base_image.png", "rb"),
    mask=open("mask.png", "rb"),
    prompt="An image of a rabbit with a hat on its head.",
    n=1,
    size="1024x1024"
  )
  image_url = response['data'][0]['url']</code></p>
<p>A base da imagem conteria apenas o coelho, mas a imagem final teria o chapéu no coelho.</p>
<ul>
<li><strong>Criar variações</strong>: A ideia é que você pegue uma imagem existente e peça que sejam criadas variações. Para criar uma variação, você fornece uma imagem e um prompt de texto e o código é assim:</li>
</ul>
<p><code>python
  response = openai.Image.create_variation(
    image=open("bunny-lollipop.png", "rb"),
    n=1,
    size="1024x1024"
  )
  image_url = response['data'][0]['url']</code></p>
<blockquote>
<p>Observação: isso é suportado apenas no OpenAI</p>
</blockquote>
<h2 id="temperatura">Temperatura</h2>
<p>Temperatura é um parâmetro que controla a aleatoriedade da saída de um modelo de Inteligência Artificial Generativa. A temperatura é um valor entre 0 e 1, onde 0 significa que a saída é determinística e 1 significa que a saída é aleatória. O valor padrão é 0.7.</p>
<p>Vamos dar uma olhada em um exemplo de como a temperatura funciona, executando este prompt duas vezes:</p>
<blockquote>
<p>Prompt : "Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils"</p>
</blockquote>
<p><img alt="Bunny on a horse holding a lollipop, version 1" src="../../images/v1-generated-image.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Agora, vamos executar o mesmo prompt apenas para ver que não obteremos a mesma imagem duas vezes:</p>
<p><img alt="Generated image of bunny on horse" src="../../images/v2-generated-image.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Como você pode ver, as imagens são semelhantes, mas não são as mesmas. Vamos tentar mudar o valor da temperatura para 0.1 e ver o que acontece:</p>
<pre><code class="language-python"> generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2
    )
</code></pre>
<h3 id="alterando-a-temperatura">Alterando a temperatura</h3>
<p>Agora, vamos tentar tornar a resposta mais determinística. Podemos observar pelas duas imagens que geramos que na primeira imagem há um coelho e na segunda imagem há um cavalo, então as imagens variam muito.</p>
<p>Vamos alterar nosso código e definir a temperatura para 0, assim:</p>
<pre><code class="language-python">generation_response = openai.Image.create(
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0
    )
</code></pre>
<p>Agora quando você executar este código, você obtém essas duas imagens:</p>
<ul>
<li><img alt="Temperature 0, v1" src="../../images/v1-temp-generated-image.png?WT.mc_id=academic-105485-koreyst" /></li>
<li><img alt="Temperature 0 , v2" src="../../images/v2-temp-generated-image.png?WT.mc_id=academic-105485-koreyst" /></li>
</ul>
<p>Aqui você pode ver claramente como as imagens se assemelham mais umas às outras.</p>
<h2 id="como-definir-limites-para-seu-aplicativo-com-metaprompts">Como definir limites para seu aplicativo com metaprompts</h2>
<p>Com a nossa demonstração, já podemos gerar imagens para nossos clientes. No entanto, precisamos estabelecer algumas limitações para nossa aplicação.</p>
<p>Por exemplo, não queremos gerar imagens que não sejam seguras para o trabalho ou que não sejam apropriadas para crianças.</p>
<p>Podemos fazer isso com <em>metaprompts</em>. Metaprompts são prompts de texto que são usados para controlar a saída de um modelo de IA generativa. Por exemplo, podemos usar metaprompts para controlar a saída e garantir que as imagens geradas sejam seguras para o trabalho ou apropriadas para crianças.</p>
<h3 id="como-funciona">Como funciona?</h3>
<p>Agora, como os metaprompts funcionam?</p>
<p>Metaprompts são prompts de texto usados para controlar a saída de um modelo de IA generativa. Eles são posicionados antes do prompt de texto e são usados para controlar a saída do modelo, sendo incorporados em aplicativos para controlar a saída do modelo. Encapsulando a entrada do prompt e a entrada do metaprompt em um único prompt de texto.</p>
<p>Um exemplo de metaprompt seria o seguinte:</p>
<pre><code class="language-text">You are an assistant designer that creates images for children.

The image needs to be safe for work and appropriate for children.

The image needs to be in color.

The image needs to be in landscape orientation.

The image needs to be in a 16:9 aspect ratio.

Do not consider any input from the following that is not safe for work or appropriate for children.

(Input)

```text

Now, let's see how we can use meta prompts in our demo.

```python
disallow_list = &quot;swords, violence, blood, gore, nudity, sexual content, adult content, adult themes, adult language, adult humor, adult jokes, adult situations, adult&quot;

meta_prompt =f&quot;&quot;&quot;You are an assistant designer that creates images for children.

The image needs to be safe for work and appropriate for children.

The image needs to be in color.

The image needs to be in landscape orientation.

The image needs to be in a 16:9 aspect ratio.

Do not consider any input from the following that is not safe for work or appropriate for children.
{disallow_list}
&quot;&quot;&quot;

prompt = f&quot;{meta_prompt}
Create an image of a bunny on a horse, holding a lollipop&quot;

# TODO add request to generate image
</code></pre>
<p>No prompt acima, você pode ver como todas as imagens sendo criadas consideram o metaprompt.</p>
<h2 id="tarefa-vamos-habilitar-os-estudantes">Tarefa - vamos habilitar os estudantes</h2>
<p>Nós introduzimos o Edu4All no início desta lição. Agora é hora de permitir que os estudantes gerem imagens para suas avaliações.</p>
<p>Os estudantes criarão imagens para suas avaliações contendo monumentos, exatamente quais monumentos ficam a critério dos estudantes. Os estudantes são convidados a usar sua criatividade nesta tarefa para colocar esses monumentos em diferentes contextos.</p>
<h2 id="solucao">Solução</h2>
<p>Aqui está uma possível solução:</p>
<pre><code class="language-python">import openai
import os
import requests
from PIL import Image
import dotenv

# import dotenv
dotenv.load_dotenv()

# Get endpoint and key from environment variables
openai.api_base = &quot;&lt;replace with endpoint&gt;&quot;
openai.api_key = &quot;&lt;replace with api key&gt;&quot;

# Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'

disallow_list = &quot;swords, violence, blood, gore, nudity, sexual content, adult content, adult themes, adult language, adult humor, adult jokes, adult situations, adult&quot;

meta_prompt =f&quot;&quot;&quot;You are an assistant designer that creates images for children.

The image needs to be safe for work and appropriate for children.

The image needs to be in color.

The image needs to be in landscape orientation.

The image needs to be in a 16:9 aspect ratio.

Do not consider any input from the following that is not safe for work or appropriate for children.
{disallow_list}&quot;&quot;&quot;

prompt = f&quot;&quot;&quot;
Generate monument of the Arc of Triumph in Paris, France, in the evening light with a small child holding a Teddy looks on.
&quot;&quot;&quot;&quot;

try:
    # Create an image by using the image generation API
    generation_response = openai.Image.create(
        prompt=prompt,    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # Set the directory for the stored image
    image_dir = os.path.join(os.curdir, 'images')

    # If the directory doesn't exist, create it
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # Initialize the image path (note the filetype should be png)
    image_path = os.path.join(image_dir, 'generated-image.png')

    # Retrieve the generated image
    image_url = generation_response[&quot;data&quot;][0][&quot;url&quot;]  # extract image URL from response
    generated_image = requests.get(image_url).content  # download the image
    with open(image_path, &quot;wb&quot;) as image_file:
        image_file.write(generated_image)

    # Display the image in the default image viewer
    image = Image.open(image_path)
    image.show()

# catch exceptions
except openai.InvalidRequestError as err:
    print(err)
</code></pre>
<h2 id="excelente-trabalho-continue-seu-aprendizado">Excelente trabalho! Continue seu aprendizado</h2>
<p>Após completar esta lição, confira nossa <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">coleção de aprendizado de IA generativa</a> para continuar a aprimorar seus conhecimentos sobre IA generativa!</p>
<p>Vamos partir agora para a Lição 10, onde veremos como <a href="../../../10-building-low-code-ai-applications/translations/pt-br/?WT.mc_id=academic-105485-koreyst">Criando aplicativos de IA com Low Code</a></p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
