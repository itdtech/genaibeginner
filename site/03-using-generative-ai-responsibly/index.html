<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Using Generative AI Responsibly - genaibeginner</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Using Generative AI Responsibly";
        var mkdocs_page_input_path = "03-using-generative-ai-responsibly\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../00-course-setup/translations/cn/">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../09-building-image-applications/translations/cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Using Generative AI Responsibly</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="using-generative-ai-responsibly">Using Generative AI Responsibly</h1>
<p><a href="https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst"><img alt="Using Generative AI Responsibly" src="images/03-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<blockquote>
<p><em>Click the image above to view video of this lesson</em></p>
</blockquote>
<p>It's easy to be fascinated with AI and generative AI in particular, but you need to consider how you would use it responsibly. You need to consider things like how to ensure the output is fair, non-harmful and more. This chapter aims to provide you with the mentioned context, what to consider, and how to take active steps to improve your AI usage.</p>
<h2 id="introduction">Introduction</h2>
<p>This lesson will cover:</p>
<ul>
<li>Why you should prioritize Responsible AI when building Generative AI applications.</li>
<li>Core principles of Responsible AI and how they relate to Generative AI.</li>
<li>How to put these Responsible AI principles into practice through strategy and tooling.</li>
</ul>
<h2 id="learning-goals">Learning Goals</h2>
<p>After completing this lesson you will know:</p>
<ul>
<li>The importance of Responsible AI when building Generative AI applications.</li>
<li>When to think and apply the core principles of Responsible AI when building Generative AI applications.</li>
<li>What tools and strategies are available to you to put the concept of Responsible AI into practice.</li>
</ul>
<h2 id="responsible-ai-principles">Responsible AI Principles</h2>
<p>The excitement of Generative AI has never been higher. This excitement has brought a lot of new developers, attention, and funding to this space. While this is very positive for anyone looking to build products and companies using Generative AI, it is also important we proceed responsibly.</p>
<p>Throughout this course, we are focusing on building our startup and our AI education product. We’ll use the principles of Responsible AI: Fairness, Inclusiveness, Reliability/Safety, Security &amp; Privacy, Transparency and Accountability. With these principles, we will explore how they relate to our use of Generative AI in our products.</p>
<h2 id="why-should-you-prioritize-responsible-ai">Why Should You Prioritize Responsible AI</h2>
<p>When building a product, taking a human-centric approach by keeping your user's best interest in mind leads to the best results.</p>
<p>The uniqueness of Generative AI is its power to create helpful answers, information, guidance, and content for users. This can be done without many manual steps which can lead to very impressive results. Without proper planning and strategies, it can also unfortunately lead to some harmful results for your users, your product, and society as a whole.</p>
<p>Let's look at some (but not all) of these potentially harmful results:</p>
<h3 id="hallucinations">Hallucinations</h3>
<p>Hallucinations are a term used to describe when an LLM produces content that is either completely nonsensical or something we know is factually wrong based on other sources of information.</p>
<p>Let's take for example we build a feature for our startup that allows students to ask historical questions to a model. A student asks the question <code>Who was the sole survivor of Titanic?</code></p>
<p>The model produces a response such as the one below:</p>
<p><img alt="Prompt saying &quot;Who was the sole survivor of the Titanic&quot;" src="images/ChatGPT-titanic-survivor-prompt.webp?WT.mc_id=academic-105485-koreyst" /></p>
<blockquote>
<p><em>(Source: <a href="https://flyingbisons.com?WT.mc_id=academic-105485-koreyst">Flying bisons</a>)</em></p>
</blockquote>
<p>This is a very confident and thorough answer. Unfortunately, it is incorrect. Even with a minimal amount of research, one would discover there was more than one survivor of the Titanic disaster. For a student who is just starting to research this topic, this answer can be persuasive enough to not be questioned and treated as fact. The consequences of this can lead to the AI system being unreliable and negatively impact the reputation of our startup.</p>
<p>With each iteration of any given LLM, we have seen performance improvements around minimizing hallucinations. Even with this improvement, we as application builders and users still need to remain aware of these limitations.</p>
<h3 id="harmful-content">Harmful Content</h3>
<p>We covered in the earlier section when an LLM produces incorrect or nonsensical responses. Another risk we need to be aware of is when a model responds with harmful content.</p>
<p>Harmful content can be defined as:</p>
<ul>
<li>Providing instructions or encouraging self-harm or harm to certain groups.</li>
<li>Hateful or demeaning content.</li>
<li>Guiding planning any type of attack or violent acts.</li>
<li>Providing instructions on how to find illegal content or commit illegal acts.</li>
<li>Displaying sexually explicit content.</li>
</ul>
<p>For our startup, we want to make sure we have the right tools and strategies in place to prevent this type of content from being seen by students.</p>
<h3 id="lack-of-fairness">Lack of Fairness</h3>
<p>Fairness is defined as “ensuring that an AI system is free from bias and discrimination and that they treat everyone fairly and equally.” In the world of Generative AI, we want to ensure that exclusionary worldviews of marginalized groups are not reinforced by the model’s output.</p>
<p>These types of outputs are not only destructive to building positive product experiences for our users, but they also cause further societal harm. As application builders, we should always keep a wide and diverse user base in mind when building solutions with Generative AI.</p>
<h2 id="how-to-use-generative-ai-responsibly">How to Use Generative AI Responsibly</h2>
<p>Now that we have identified the importance of Responsible Generative AI, let's look at 4 steps we can take to build our AI solutions responsibly:</p>
<p><img alt="Mitigate Cycle" src="images/mitigate-cycle.png?WT.mc_id=academic-105485-koreyst" /></p>
<h3 id="measure-potential-harms">Measure Potential Harms</h3>
<p>In software testing, we test the expected actions of a user on an application. Similarly, testing a diverse set of prompts users are most likely going to use is a good way to measure potential harm.</p>
<p>Since our startup is building an education product, it would be good to prepare a list of education-related prompts. This could be to cover a certain subject, historical facts, and prompts about student life.</p>
<h3 id="mitigate-potential-harms">Mitigate Potential Harms</h3>
<p>It is now time to find ways where we can prevent or limit the potential harm caused by the model and its responses. We can look at this in 4 different layers:</p>
<p><img alt="Mitigation Layers" src="images/mitigation-layers.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>
<p><strong>Model</strong>. Choosing the right model for the right use case. Larger and more complex models like GPT-4 can cause more of a risk of harmful content when applied to smaller and more specific use cases. Using your training data to fine-tune also reduces the risk of harmful content.</p>
</li>
<li>
<p><strong>Safety System</strong>. A safety system is a set of tools and configurations on the platform serving the model that help mitigate harm. An example of this is the content filtering system on the Azure OpenAI service. Systems should also detect jailbreak attacks and unwanted activity like requests from bots.</p>
</li>
<li>
<p><strong>Metaprompt</strong>. Metaprompts and grounding are ways we can direct or limit the model based on certain behaviors and information. This could be using system inputs to define certain limits of the model. In addition, providing outputs that are more relevant to the scope or domain of the system.</p>
</li>
</ul>
<p>It can also be using techniques like Retrieval Augmented Generation (RAG) to have the model only pull information from a selection of trusted sources. There is a lesson later in this course for <a href="../08-building-search-applications/?WT.mc_id=academic-105485-koreyst">building search applications</a></p>
<ul>
<li><strong>User Experience</strong>. The final layer is where the user interacts directly with the model through our application’s interface in some way. In this way we can design the UI/UX to limit the user on the types of inputs they can send to the model as well as text or images displayed to the user. When deploying the AI application, we also must be transparent about what our Generative AI application can and can’t do.</li>
</ul>
<p>We have an entire lesson dedicated to <a href="../12-designing-ux-for-ai-applications/?WT.mc_id=academic-105485-koreyst">Designing UX for AI Applications</a></p>
<ul>
<li><strong>Evaluate model</strong>. Working with LLMs can be challenging because we don’t always have control over the data the model was trained on. Regardless, we should always evaluate the model’s performance and outputs. It’s still important to measure the model’s accuracy, similarity, groundedness, and relevance of the output. This helps provide transparency and trust to stakeholders and users.</li>
</ul>
<h3 id="operate-a-responsible-generative-ai-solution">Operate a Responsible Generative AI solution</h3>
<p>Building an operational practice around your AI applications is the final stage. This includes partnering with other parts of our startup like Legal and Security to ensure we are compliant with all regulatory policies. Before launching, we also want to build plans around delivery, handling incidents, and rollback to prevent any harm to our users from growing.</p>
<h2 id="tools">Tools</h2>
<p>While the work of developing Responsible AI solutions may seem like a lot, it is work well worth the effort. As the area of Generative AI grows, more tooling to help developers efficiently integrate responsibility into their workflows will mature. For example, the <a href="https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst">Azure AI Content Safety</a> can help detect harmful content and images via an API request.</p>
<h2 id="knowledge-check">Knowledge check</h2>
<p>What are some things you need to care about to ensure responsible AI usage?</p>
<ol>
<li>That the answer is correct.</li>
<li>Harmful usage, that AI isn't used for criminal purposes.</li>
<li>Ensuring the AI is free from bias and discrimination.</li>
</ol>
<p>A: 2 and 3 are correct. Responsible AI helps you consider how to mitigate harmful effects and biases and more.</p>
<h2 id="challenge">🚀 Challenge</h2>
<p>Read up on <a href="https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst">Azure AI Content Saftey</a> and see what you can adopt for your usage.</p>
<h2 id="great-work-continue-your-learning">Great Work, Continue Your Learning</h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>
<p>Head over to Lesson 4 where we will look at <a href="../04-prompt-engineering-fundamentals/?WT.mc_id=academic-105485-koreyst">Prompt Engineering Fundamentals</a>!</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
