<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>さまざまな LLM の調査と比較 - genaibeginner</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u3055\u307e\u3056\u307e\u306a LLM \u306e\u8abf\u67fb\u3068\u6bd4\u8f03";
        var mkdocs_page_input_path = "02-exploring-and-comparing-different-llms\\translations\\ja-jp\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../00-course-setup/translations/cn/">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../09-building-image-applications/translations/cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">さまざまな LLM の調査と比較</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="llm">さまざまな LLM の調査と比較</h1>
<p><a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst"><img alt="Exploring and comparing different LLMs" src="../../images/02-lesson-banner.png?WT.mc_id=academic-105485-yoterada" /></a></p>
<blockquote>
<p><em>(上記の画像をクリックすると、レッスン・ビデオを表示します)</em></p>
</blockquote>
<p>前回のレッスンで、生成 AI がどのようにして進化し、大規模言語モデル（LLM）がどのように機能するのか、そしてスタートアップがそれらを自分たちの目的に対して、どのように適用し成長できるかを見てきました。この章では、様々な大規模言語モデル（LLM）を比較し、それぞれの利点と欠点を理解していきます。</p>
<p>スタートアップは、大規模言語モデル（LLM）の最新状況を調査し、自社のニーズに適したモデルが何かを検討する段階に移りました。</p>
<h2 id="_1">はじめに</h2>
<p>このレッスンでは、下記の内容について説明します。</p>
<ul>
<li>いま存在する様々な種類の LLM（大規模言語モデル）について学ぶ</li>
<li>Azure で用途に応じて異なる AI モデルを選択しテスト、反復作業、及び比較を行う</li>
<li>LLM のデプロイ方法について学ぶ</li>
</ul>
<h2 id="_2">学習目標</h2>
<p>このレッスンを修了すると、下記を理解できます：</p>
<ul>
<li>ユースケースに適したモデルを選択する</li>
<li>モデルのパフォーマンスをテストし、反復し、そして改善する方法を理解する</li>
<li>企業がどのようにモデルをデプロイするかを知る</li>
</ul>
<h2 id="llm_1">大規模言語モデル（LLM）の様々な種類の理解</h2>
<p>大規模言語モデル（LLM）は、そのアーキテクチャ、トレーニングデータ、用途に応じて、様々なカテゴリに分類できます。こうした各モデルの把握は、スタートアップがシナリオに応じて最適なモデルを選択し、パフォーマンスのテストを行い、反復しながら改善するのに役立ちます。</p>
<p>LLM モデルには、さまざまな種類があり、どのモデルを選択するかは、それらを使用する目的、扱うデータ、ご利用可能な金額などによって異なります。</p>
<p>選択するモデルは、テキスト、オーディオ、ビデオ、画像の生成など、各用途に応じてそれぞれ異なる種類のモデルを選択します。</p>
<ul>
<li>
<p><strong>オーディオおよび音声認識</strong>：この用途には、音声認識として汎用性のある Whisper というモデルが最適です。このモデルは、様々なオーディオ・データでトレーニングされており、多言語にも対応した音声認識ができます。<a href="https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-yoterada">Whisper のモデルについての詳細はこちら</a>.</p>
</li>
<li>
<p><strong>画像生成</strong>：画像生成の選択肢としては、DALL-E と Midjourney が非常に有名です。Azure OpenAI 上で DALL-E のモデルが利用可能です。<a href="https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-yoterada">DALL-E についての詳細はこちら</a>をご覧ください。このカリキュラムの第 9 章でも解説します。</p>
</li>
<li>
<p><strong>テキスト生成</strong>：多くのモデルがテキスト生成用にトレーニングされており、GPT-3.5 から GPT-4 に至るまで、多種多様な選択肢があります。それぞれ利用する際のコストは異なり、GPT-4 が最も高価です。機能とコストの観点から、ニーズに最も適したモデルを選択するために、<a href="https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-yoterada">Azure OpenAI プレイグラウンド</a>をご確認ください。</p>
</li>
</ul>
<p>モデルを選択すると、基本的な機能を手に入れ、モデルを利用できるようになっていますが、それだけでは不十分です。通常、会社固有のデータを何らかの方法で LLM に伝えなければならない場合もあります。その方法はいくつかの選択肢がありますが、それについては後続のセクションで詳しく説明します。</p>
<h3 id="llm_2">ファウンデーション・モデルと LLM の比較</h3>
<p>「ファウンデーション・モデル」という用語はスタンフォード大学の研究者たちが提唱し、以下のような基準に従う AI モデルとして定義しています。</p>
<ul>
<li><strong>教師なし学習、または自己教師あり学習でトレーニング</strong>：ラベルのないマルチモーダル・データを用いてトレーニングし、トレーニング・プロセス中、人間によるデータの注釈やラベル付けは不要です</li>
<li><strong>非常に大規模なモデル</strong>：数十億のパラメーターを用いてトレーニングされたディープ・ニューラル・ネットワークに基づいています</li>
<li><strong>通常、他のモデルの「基盤」として使用</strong>：ファイン・チューニングを行い、他のモデルを構築する際の基盤として使用できます</li>
</ul>
<p><img alt="ファウンデーション・モデルと LLM" src="../../images/FoundationModel.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>画像出展: <a href="https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404">基盤モデルと大規模言語モデルの効果的なガイド | Babar M Bhatti 著 | Medium</a></p>
<p>この違いをさらに明確にするために、ChatGPT を例に挙げてみましょう。ChatGPT の最初のバージョンを作る際 GPT-3.5 というモデルをファウンデーション・モデルとして使いました。つまり、OpenAI は、チャットボットのような会話シナリオで高いパフォーマンスを発揮するよう、チャットに特化したデータを用いて GPT-3.5 のチューニング版を作成したのです。</p>
<p><img alt="Foundation Model" src="../../images/Multimodal.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>画像出展: <a href="https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-yoterada">2108.07258.pdf (arxiv.org)</a></p>
<h3 id="_3">オープンソース・モデルとプロプライエタリ・モデル</h3>
<p>大規模言語モデル（LLM）を分類する別の方法として、それがオープンソースなのか、もしくはプロプライエタリな物なのか、という観点もあります。</p>
<p>オープンソース・モデルは、一般に公開され、誰でも利用できるモデルです。これらは多くの場合、そのモデルを開発した企業や研究コミュニティによって提供されます。これらのモデルは、LLM の様々な用途に合わせて検証、変更、カスタマイズの許可がされています。しかし、常に本番環境での利用に最適化されているわけではなく、プロプライエタリモデルほど高いパフォーマンスを発揮しない場合もあります。さらに、オープンソース・モデルの資金調達は限られており、長期的に継続できない可能性や、最新の研究に基づいて更新されていない可能性もあります。<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-yoterada">Alpaca</a>、<a href="https://huggingface.co/bigscience/bloom">Bloom</a>、<a href="https://llama.meta.com">LLaMA</a> などが人気のオープンソース・モデルの例です。</p>
<p>プロプライエタリ・モデルは、企業が所有し一般には公開されていないモデルです。これらのモデルは、通常本番環境での利用に最適化されています。しかし異なるユースケースに対して、検証、変更、カスタマイズは許可されていません。また、常に無料で利用できるわけではなく、利用するためには、サブスクリプション等による支払いが必要な場合もあります。さらに、利用者はモデルをトレーニングする際に使用するデータをコントロールできず、データのプライバシーや、責任ある AI の原則に基づく使用をモデル・プロバイダが保証しているのを信用しなければなりません。<a href="https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-yoterada">OpenAI のモデル</a>、<a href="https://sapling.ai/llm/bard?WT.mc_id=academic-105485-yoterada">Google Bard</a>、<a href="https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-yoterada">Claude 2</a> などが人気のプロプライエタリ・モデルです。</p>
<h3 id="embedding">埋め込み (Embedding) と画像生成とテキスト・コード生成</h3>
<p>大規模言語モデル(LLM) は出力の種類によっても分類できます。</p>
<p>埋め込み (Embedding) は、テキストを、「埋め込みと」呼ぶ数値形式に変換する AI モデルです。言い換えるならば、埋め込みは入力されたテキストに対する数値表現です。埋め込みによって、機械が単語や文の関係を理解しやすくなり、分類モデルや、数値データでパフォーマンスが向上するクラスタリング・モデルなど、他のモデルの入力として利用できます。埋め込みモデルは、たくさんのデータがある代理タスク用にモデルが作成され、モデルの重み（埋め込み）を、他の下流タスクで再利用する転移学習によく使用されます。このカテゴリーの例としては、<a href="https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-yoterada">OpenAI Embeddings</a> モデルがあります。</p>
<p><img alt="Embedding" src="../../images/Embedding.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>画像生成モデルは、画像を生成するモデルです。これらのモデルは、画像編集、画像合成、画像変換で頻繁に利用されます。画像生成モデルは、<a href="https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-yoterada">LAION-5B</a> などの大規模な画像データセットでトレーニングするのが多く、新しい画像を生成したり、画像修復、高解像度化、色付け技術を用いて既存の画像を編集する際に利用できます。<a href="https://openai.com/dall-e-3?WT.mc_id=academic-105485-yoterada">DALL-E-3</a> や <a href="https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-yoterada">Stable Diffusion models</a> といったモデルがあります。</p>
<p><img alt="Image generation" src="../../images/Image.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>テキスト生成モデルとコード生成モデルは、テキストやコードを生成するためのモデルです。これらのモデルは、テキストの要約、翻訳、質疑応答などによく利用されます。テキスト生成モデルは、<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-yoterada">BookCorpus</a> などの大規模なテキストデータセットでトレーニングされ、新しいテキストを生成したり、質問に答えたりするのに使われます。<a href="https://huggingface.co/codeparrot?WT.mc_id=academic-105485-yoterada">CodeParrot</a> のようなコード生成モデルは、GitHub など大量のソースコード・データでトレーニングされ、新しいコードを生成したり、既存コードのバグ修正などで使われます。
<img alt="Text and code generation" src="../../images/Text.png?WT.mc_id=academic-105485-yoterada" /></p>
<h3 id="_4">「エンコーダー・デコーダー」 と 「デコーダーのみ」 のモデル</h3>
<p>大規模言語モデル (LLM) のアーキテクチャの種類の違いについて解説するため、下記の例え話しを使います。</p>
<p>上司から、学生用のクイズを作成する仕事を任されたのを想像してください。あなたには 2 人の同僚がいて、1 人はコンテンツの作成を担当し、もう 1 人はそれをレビューする役割を担います。</p>
<p>コンテンツを作成する人は「デコーダーのみ」のモデルに似ています。コンテンツ作成者は、トピックを見て、既に書いた内容を参考に、それに基づいてコンテンツを作成します。コンテンツ作成者は、魅力的で情報豊かなコンテンツを作成するのが得意ですが、トピックや学習目標を理解するのは得意ではありません。「デコーダーのみ」のモデルの例には、GPT-3 などの GPT ファミリーのモデルがあります。</p>
<p>一方で、レビュー担当者は「エンコーダーのみ」のモデルに似ています。レビュー担当者は書かれた内容と回答を見て、それらの関係を把握し、文脈を理解しますが、コンテンツを作成するのは得意ではありません。「エンコーダーのみ」のモデルの例には、BERT があります。</p>
<p>クイズを作成し、それをレビューする同一人物がいるのを想像してみてください。これが「エンコーダー・デコーダー」モデルです。BART や T5 などが例として挙げられます。</p>
<h3 id="_5">サービスとモデル</h3>
<p>サービスとモデルの違いについて説明します。サービスはクラウド・サービス・プロバイダーが提供する製品で、モデル、データ、その他のコンポーネントを組み合わせたものです。モデルはサービスの核となる部分で、大規模言語モデル (LLM) のようなファウンデーション・モデルが一般的です。</p>
<p>サービスは、本番環境での利用に最適化されており、グラフィカル・ユーザー・インターフェースを通じて、直接モデルを操作するのに比べ扱いやすくなっています。しかしサービスは、常に無料で利用できるわけではなく、サービス提供者の機器やリソースを活用する代わりに、サブスクリプション等による支払いが必要な場合があります。これにより、費用を最適化し、簡単にスケールアップできます。サービスの例としては、使用量に応じて料金が発生する <a href="https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-yoterada">Azure OpenAI Service</a> があります。また、Azure OpenAI サービスは、モデルの能力に加え、エンタープライズグレードのセキュリティと責任ある AI のフレームワークも提供しています。</p>
<p>モデルは、パラメーターや重みなどを含むニューラルネットワークそのものです。企業はローカルでの運用も可能ですが、そのためには機器の購入、スケールアップのための環境構築、ライセンスの購入、またはオープンソース・モデルの使用が必要になります。LLaMA のようなモデルは利用可能ですが、モデルを実行するためには計算資源が必要です。</p>
<h2 id="azure">Azure でパフォーマンスを理解するために異なるモデルでテストと反復処理を行う方法</h2>
<p>現在の LLM の状況を調査し、シナリオに適したモデルの候補を見つけたら、次に企業の実データと負荷試験でそれらをテストする必要があります。これは実験と検証を通じて行われる反復的なプロセスです。前の段落で触れたモデル（OpenAI モデル、Llama2 のようなオープンソースモデル、Hugging Face のトランスフォーマー）のほとんどは、<a href="https://ml.azure.com/?WT.mc_id=academic-105485-yoterada">Azure Machine Learning Studio</a> の<a href="https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-yoterada">ファウンデーション・モデル・カタログ</a>で利用可能です。</p>
<p><a href="https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-yoterada">Azure Machine Learning</a> は、データ・サイエンティストと機械学習エンジニアが ML ライフサイクル全体（トレーニング、テスト、デプロイ、MLOps の管理）を一つのプラットフォームで管理するために設計されたクラウド・サービスです。Machine Learning Studio はグラフィカル・ユーザー・インターフェースを提供し、利用者は下記の操作を行えます：</p>
<ul>
<li>カタログから興味のあるファウンデーション・モデルを探し、タスク、ライセンス、名前でフィルタリングできます。カタログにまだ含まれていない新しいモデルもインポートできます。</li>
<li>モデル・カードを確認して、詳細な説明とコードサンプルを見て、サンプル推論ウィジェットを使ってテストします。これは、サンプルのプロンプトを入力して回答結果を試すために利用します。</li>
</ul>
<p><img alt="Model card" src="../../images/Llama1.png?WT.mc_id=academic-105485-yoterada" /></p>
<ul>
<li>特定の負荷試験と、入力した特定のデータセットに関する客観的な評価指標を用いて、モデルのパフォーマンスを評価します。</li>
</ul>
<p><img alt="Model evaluation" src="../../images/Llama2.png?WT.mc_id=academic-105485-yoterada" /></p>
<ul>
<li>Azure Machine Learning の実験と追跡機能を活用して、カスタム・トレーニングデータでモデルをファイン・チューニングし、特定の負荷試験におけるモデルのパフォーマンスを向上させます。</li>
</ul>
<p><img alt="Model fine-tuning" src="../../images/Llama3.png?WT.mc_id=academic-105485-yoterada" /></p>
<ul>
<li>元の事前トレーニング済みモデル、もしくはファイン・チューニングしたバージョンをリモートのリアルタイム推論、もしくはバッチ・エンドポイントにデプロイし、アプリケーションから利用できるようにします。</li>
</ul>
<p><img alt="Model deployment" src="../../images/Llama4.png?WT.mc_id=academic-105485-yoterada" /></p>
<h2 id="llm_3">大規模言語モデル (LLM) の出力結果を改善する</h2>
<p>スタートアップ・チームは、さまざまな種類の大規模言語モデル (LLM) とクラウド・プラットフォームのサービス（Azure Machine Learning）を理解し、異なるモデルを比較し、テストデータで評価し、パフォーマンスを向上させ、推論エンドポイントにデプロイする方法を検討しました。</p>
<p>しかし、事前トレーニングされたモデルを使用するのではなく、モデルをファイン・チューニングするのを検討すべきタイミングはいつでしょうか？特定の負荷試験でモデルのパフォーマンスを向上させる他のアプローチはあるのでしょうか？</p>
<p>企業が大規模言語モデル（LLM）を利用して、期待する結果を得るためには、トレーニング・レベルの異なる様々な手法からも選択できます。</p>
<p>異なる実装方法（容易 → 困難）、コスト（低額 → 高額）、品質(低 → 高) から実装方法を検討し、LLM を本番環境にデプロイできます。以下に、いくつかの異なるアプローチを紹介します。</p>
<ul>
<li>
<p><strong>コンテキストを用いたプロンプトエンジニアリング</strong>：プロンプトを記述する際に十分なコンテキストを提供し、必要な回答を得るのが狙いです。</p>
</li>
<li>
<p><strong>Retrieval Augmented Generation（RAG）</strong>：例えば、データがデータ・ベースや Web 上に存在する場合、関連データを取得し、プロンプトの記述時に、それらデータの一部をプロンプトに含めます。</p>
</li>
<li>
<p><strong>ファイン・チューニングしたモデル</strong>：自分のデータを利用してモデルをさらにトレーニングし、モデルをより正確に、そしてニーズに応じた形にします。ただし、コストがかかる可能性があります。</p>
</li>
</ul>
<p><img alt="LLMs deployment" src="../../images/Deploy.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>画像出展:: <a href="https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-yoterada">Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog</a></p>
<h3 id="_6">コンテキストを用いたプロンプトエンジニアリング</h3>
<p>事前学習済みの大規模言語モデル（LLM）は、一般的な自然言語タスクとして、例えば、文の作成や質問などの処理をリクエストする際、短いプロンプトの呼び出しだけで、とても良い結果を出力します。これを「ゼロショット」学習と呼びます。</p>
<p>しかし、詳細なリクエストや具体例を用いて問い合わせ内容を記述すると、つまり追加のコンテキストを提供すると、回答はより正確で利用者の期待値に近い内容になります。この場合、プロンプトに一つの例が含まれている場合は「ワンショット」学習、複数の例が含まれている場合は「フュー・ショット」学習と言います。コンテキストを用いたプロンプト・エンジニアリングは、一番最初に実施すべき改善点で、そして最もコスト効率の高いアプローチです。</p>
<h3 id="retrieval-augmented-generationrag">Retrieval Augmented Generation（RAG）</h3>
<p>LLM は、モデルのトレーニング中に使用したデータだけを使って回答を作るという制約があります。つまり、トレーニング・プロセス後に発生した事実については何も分からず、非公開情報 (企業データなど) も利用できません。</p>
<p>しかし、上記の制約は RAG と呼ぶ手法で対応できます。RAG は、プロンプトの長さ制限を考慮しつつ、外部データ（ドキュメントの一部）をプロンプト内に含めて問い合わせを行う手法です。
RAG は Vector データベース（<a href="https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-yoterada">Azure AI Search</a> など）でサポートされており、さまざまな定義済みのデータ・ソースから有用なドキュメントの一部を取得し、プロンプトのコンテキスト（文脈）に含めて、より正確な回答が得られるようになります。</p>
<p>この技術は、LLM のファイン・チューニングが困難（十分なデータ、時間、リソースがない）な企業にとって非常に有用です。
そして特定の負荷試験におけるパフォーマンスを向上させたい場合や、回答の捏造リスク、つまり現実の歪曲や、有害なコンテンツのリスクを減らしたい場合に非常に有効です。</p>
<h3 id="_7">ファイン・チューニングしたモデルの利用</h3>
<p>ファイン・チューニングは、転移学習を活用してモデルを下流タスクに「適応」させたり、特定の問題を解決するプロセスです。上記のフュー・ショット学習や、RAG とは異なり、更新した重みとバイアスを持つ新しいモデルを生成します。これには、入力（プロンプト）とそれに関連する出力（Completion）から構成する大量のトレーニング・データが必要です。このアプローチは、下記のような場合に有効です：</p>
<ul>
<li>
<p><strong>ファイン・チューニングしたモデルを使用する場合</strong>：企業が高性能なモデルではなく、ファイン・チューニングした能力の低いモデル（埋め込みモデルなど）を使用し、よりコスト効率を高く、迅速なソリューション提供したいと考えている場合</p>
</li>
<li>
<p><strong>レイテンシーを考慮する場合</strong>：特定の用途でレイテンシーが重要で、とても長いプロンプトを使用できない、またはモデルから学習するサンプル数がプロンプトの長さ制限に合わないような場合</p>
</li>
<li>
<p><strong>最新の状態を維持する場合</strong>：企業が高品質のデータと正確なラベルを多く持ち、これらのデータを時間をかけて最新の状態に保つためのリソースを持っている場合</p>
</li>
</ul>
<h3 id="_8">トレーニング済みモデル</h3>
<p>LLM をゼロからトレーニングするのは、間違いなく最も困難で最も複雑なアプローチです。膨大なデータ、熟練したリソース、適切な計算能力が必要です。このオプションは、ビジネスがドメイン固有のユースケースと大量のドメイン中心のデータを持っている場合にのみ検討すべきです。</p>
<h2 id="_9">知識チェック</h2>
<p>LLM からの出力結果を改善するための良いアプローチは何でしょうか？</p>
<ol>
<li>コンテキストを用いたプロンプトエンジニアリング</li>
<li>RAG</li>
<li>ファイン・チューニングしたモデル</li>
</ol>
<p>A: 3、時間とリソース、高品質のデータがある場合 ファイン・チューニングは最新の状態を維持するためのより良い選択肢です。しかし、改善を行うために時間がない場合は、まず RAG をご検討ください。</p>
<blockquote>
<p>[!TIP]
訳者追記：<br />
訳者的には 1,2,3 の順番で検討するのが良いと思います。ケース・バイ・ケースですが、ファイン・チューニングは、時間とリソースがある場合に検討するのが良いと思います。</p>
</blockquote>
<h2 id="challenge">🚀 Challenge</h2>
<p>ビジネスで RAG を活用する方法についてもっと学びたい方は、<a href="https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-yoterada">こちら</a>をご覧ください。</p>
<h2 id="_10">お疲れ様でした! 次のレッスンを続ける</h2>
<p>このレッスン終了後、<a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-yoterada">生成 AI 学習コレクション</a>をチェックして、生成 AI の知識をさらに深めましょう。</p>
<p>次のレッスン 3 では、<a href="../../../03-using-generative-ai-responsibly/translations/ja-jp/?WT.mc_id=academic-105485-yoterada">責任ある生成 AI の利用</a>について学びます！</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
