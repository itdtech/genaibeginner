<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Explorando e comparando diferentes LLMs - genaibeginner</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Explorando e comparando diferentes LLMs";
        var mkdocs_page_input_path = "02-exploring-and-comparing-different-llms\\translations\\pt-br\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../00-course-setup/translations/cn/">è¯¾ç¨‹ä»‹ç»å’Œå­¦ä¹ ç¯å¢ƒè®¾ç½®</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01-introduction-to-genai/translations/cn/">ç¬¬ä¸€ç« ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½å’Œ LLMs ä»‹ç»</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cn/">ç¬¬äºŒç« ï¼šæ¢ç´¢å’Œæ¯”è¾ƒä¸åŒçš„ LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../03-using-generative-ai-responsibly/translations/cn/">ç¬¬ä¸‰ç« ï¼šè´Ÿè´£ä»»åœ°ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../04-prompt-engineering-fundamentals/translations/cn/">ç¬¬å››ç« ï¼šæç¤ºå·¥ç¨‹åŸºç¡€</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../05-advanced-prompts/translations/cn/">ç¬¬äº”ç« ï¼šåˆ›å»ºé«˜çº§çš„æç¤ºå·¥ç¨‹æŠ€å·§</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../06-text-generation-apps/translations/cn/">ç¬¬å…­ç« ï¼šåˆ›å»ºæ–‡æœ¬ç”Ÿæˆåº”ç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../07-building-chat-applications/translations/cn/">ç¬¬ä¸ƒç« ï¼šåˆ›å»ºèŠå¤©åº”ç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../08-building-search-applications/translations/cn/">ç¬¬å…«ç« ï¼šåˆ›å»ºæœç´¢åº”ç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../09-building-image-applications/translations/cn/">ç¬¬ä¹ç« ï¼šåˆ›å»ºå›¾åƒåº”ç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../10-building-low-code-ai-applications/translations/cn/">ç¬¬åç« ï¼šåˆ›å»ºä½ä»£ç AIåº”ç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../11-integrating-with-function-calling/translations/cn/">ç¬¬åä¸€ç« ï¼šé›†æˆå‡½æ•°è°ƒç”¨</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../12-designing-ux-for-ai-applications/translations/cn/">ç¬¬åäºŒç« ï¼šä¸ºäººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºè®¾è®¡ç”¨æˆ·ä½“éªŒ</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../13-securing-ai-applications/translations/cn/">ç¬¬åä¸‰ç« ï¼šä¿æŠ¤AIåº”ç”¨ç¨‹åº</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../14-the-generative-ai-application-lifecycle/translations/cn/">ç¬¬åå››ç« ï¼šç”Ÿæˆå¼AIåº”ç”¨ç”Ÿå‘½å‘¨æœŸ</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../15-rag-and-vector-databases/translations/cn/">ç¬¬åäº”ç« ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆå’Œå‘é‡æ•°æ®åº“</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../16-open-source-models/translations/tw/">ç¬¬åå…­ç« ï¼šå¼€æºæ¨¡å‹</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../17-ai-agents/translations/tw/">ç¬¬åä¸ƒç« ï¼šAI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../18-fine-tuning/translations/tw/">ç¬¬åå…«ç« ï¼šå¾®è°ƒ</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../19-slm/">ç¬¬åä¹ç« ï¼šSLMæ¨¡å‹</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../20-mistral/">ç¬¬äºŒåç« ï¼šMistralçš„æ¨¡å‹</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../21-meta/">ç¬¬äºŒåä¸€ç« ï¼šMetaçš„æ¨¡å‹</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Explorando e comparando diferentes LLMs</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="explorando-e-comparando-diferentes-llms">Explorando e comparando diferentes LLMs</h1>
<p><a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreystt"><img alt="Exploring and comparing different LLMs" src="../../images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<blockquote>
<p><em>Clique na imagem acima para ver o vÃ­deo desta liÃ§Ã£o</em></p>
</blockquote>
<p>Na liÃ§Ã£o anterior, vimos como a IA generativa estÃ¡ mudando o cenÃ¡rio tecnolÃ³gico, como os Grandes Modelos de Linguagens (LLMs) funcionam e como uma empresa - como nossa startup - pode aplicÃ¡-los aos seus casos de uso e crescer! Neste capÃ­tulo, estamos procurando comparar e contrastar diferentes tipos de modelos de linguagem grandes, LLMs para entender seus prÃ³s e contras.</p>
<p>O prÃ³ximo passo na jornada de nossa startup Ã© explorar o cenÃ¡rio atual dos Grandes Modelos de Linguagem (LLMs) e entender quais sÃ£o adequados para nosso caso de uso.</p>
<h2 id="introducao">IntroduÃ§Ã£o</h2>
<p>Esta liÃ§Ã£o abordarÃ¡:</p>
<ul>
<li>Diferentes tipos de LLMs no cenÃ¡rio atual.</li>
<li>Testar, iterar e comparar diferentes modelos para seu caso de uso no Azure.</li>
<li>Como implantar um LLM.</li>
</ul>
<h2 id="objetivos-de-aprendizagem">Objetivos de aprendizagem</h2>
<p>ApÃ³s a conclusÃ£o desta liÃ§Ã£o, vocÃª serÃ¡ capaz de:</p>
<ul>
<li>Selecionar o modelo certo para seu caso de uso.</li>
<li>Entender como testar, iterar e melhorar o desempenho do seu modelo.</li>
<li>Saber como as empresas implantam modelos.</li>
</ul>
<h2 id="entenda-diferentes-tipos-de-llms">Entenda diferentes tipos de LLMs</h2>
<p>Os Grandes Modelos de Linguagem (LLMs) podem ter vÃ¡rias categorizaÃ§Ãµes com base em sua arquitetura, dados de treinamento e caso de uso. Entender essas diferenÃ§as ajudarÃ¡ nossa startup a selecionar o modelo certo para o cenÃ¡rio e entender como testar, iterar e melhorar o desempenho.</p>
<p>Existem muitos tipos diferentes de modelos LLM, sua escolha de modelo depende do que vocÃª pretende usÃ¡-los, seus dados, quanto vocÃª estÃ¡ pronto para pagar e muito mais.</p>
<p>Dependendo se vocÃª pretende usar os modelos para geraÃ§Ã£o de texto, Ã¡udio, vÃ­deo ou imagem vocÃª pode optar por um tipo diferente de modelo.</p>
<ul>
<li>
<p><strong>Reconhecimento de Ã¡udio e fala</strong>: para esse fim, os modelos do tipo Whisper sÃ£o uma Ã³tima escolha. Pois sÃ£o de propÃ³sito geral e destinados ao reconhecimento de fala. Ele Ã© treinado em Ã¡udio diversificado e pode realizar reconhecimento de fala multilÃ­ngue. Saiba mais sobre <a href="https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst">modelos do tipo Whisper aqui</a>.</p>
</li>
<li>
<p><strong>GeraÃ§Ã£o de Imagem</strong>: para geraÃ§Ã£o de imagem, DALL-E e Midjourney sÃ£o duas escolhas muito conhecidas. DALL-E Ã© oferecido pelo Azure OpenAI. <a href="https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst">Leia mais sobre DALL-E aqui</a> e tambÃ©m no CapÃ­tulo 9 deste currÃ­culo.</p>
</li>
<li>
<p><strong>GeraÃ§Ã£o de texto</strong>: a maioria dos modelos Ã© treinada na geraÃ§Ã£o de texto e vocÃª tem uma grande variedade de escolhas, desde GPT-3.5 atÃ© GPT-4. Eles vÃªm a custos diferentes, sendo o GPT-4 o mais caro. Vale a pena dar uma olhada no <a href="https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst">Azure Open AI playground</a> para avaliar quais modelos se adequam melhor Ã s suas necessidades em termos de capacidade e custo.</p>
</li>
</ul>
<p>Escolher um modelo significa que vocÃª obtÃ©m algumas capacidades bÃ¡sicas, que podem nÃ£o ser suficientes. Muitas vezes, vocÃª tem dados especÃ­ficos da empresa que precisa informar ao LLM. Existem algumas opÃ§Ãµes diferentes sobre como abordar isso, abordaremos mais sobre isso nas prÃ³ximas seÃ§Ãµes.</p>
<h3 id="modelos-de-base-versus-llms">Modelos de base versus LLMs</h3>
<p>O termo Modelo de FundaÃ§Ã£o foi <a href="https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst">criado por pesquisadores de Stanford</a> e definido como um modelo de IA que segue alguns critÃ©rios, como:</p>
<ul>
<li>
<p><strong>Eles sÃ£o treinandos usando aprendizado nÃ£o supervisionado ou aprendizado auto-supervisionado</strong>, o que significa que sÃ£o treinados em dados multimodais nÃ£o rotulados e nÃ£o requerem anotaÃ§Ã£o humana ou rotulagem de dados para seu processo de treinamento.</p>
</li>
<li>
<p><strong>Eles sÃ£o modelos muito grandes</strong>, baseados em redes neurais muito profundas treinadas em bilhÃµes de parÃ¢metros.</p>
</li>
<li>
<p><strong>Normalmente, eles sÃ£o destinados a servir como uma â€˜baseâ€™ para outros modelos</strong>, o que significa que podem ser usados como ponto de partida para outros modelos serem construÃ­dos em cima, o que pode ser feito por ajuste fino.</p>
</li>
</ul>
<p><img alt="Foundation Models versus LLMs" src="../../images/FoundationModel.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Fonte da imagem: <a href="https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?WT.mc_id=academic-105485-koreyst">Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
</a></p>
<p>Para esclarecer ainda mais essa distinÃ§Ã£o, vamos usar o ChatGPT como exemplo. Para criar a primeira versÃ£o do ChatGPT, um modelo chamado GPT-3.5 serviu como modelo fundamental. Isso significa que a OpenAI utilizou alguns dados especÃ­ficos de conversaÃ§Ã£o para criar uma versÃ£o ajustada do GPT-3.5 que foi especializada em se sair bem em cenÃ¡rios de conversaÃ§Ã£o, como chatbots.</p>
<p><img alt="Foundation Model" src="../../images/Multimodal.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Fonte da imagem: <a href="https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst">2108.07258.pdf (arxiv.org)</a></p>
<h3 id="modelos-de-codigo-aberto-versus-modelos-proprietarios">Modelos de CÃ³digo Aberto versus Modelos ProprietÃ¡rios</h3>
<p>Outra maneira de categorizar os Modelos de Linguagem de Grande Escala (LLMs) Ã© se eles sÃ£o de cÃ³digo aberto ou proprietÃ¡rios.</p>
<p>Os modelos de cÃ³digo aberto sÃ£o modelos que sÃ£o disponibilizados ao pÃºblico e podem ser usados por qualquer pessoa. Eles sÃ£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para diversos casos de uso em LLMs. No entanto, nem sempre sÃ£o otimizados para uso em produÃ§Ã£o e podem nÃ£o ser tÃ£o eficientes quanto os modelos proprietÃ¡rios. AlÃ©m disso, o financiamento para modelos de cÃ³digo aberto pode ser limitado, e eles podem nÃ£o ser mantidos a longo prazo ou nÃ£o ser atualizados com as pesquisas mais recentes. Exemplos de modelos de cÃ³digo aberto populares incluem <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst">Alpaca</a>, <a href="https://huggingface.co/bigscience/bloom">Bloom</a> e <a href="https://llama.meta.com">LLaMA</a>.</p>
<p>Os modelos proprietÃ¡rios sÃ£o modelos de propriedade de uma empresa e nÃ£o sÃ£o disponibilizados ao pÃºblico. Esses modelos sÃ£o frequentemente otimizados para uso em produÃ§Ã£o. No entanto, nÃ£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. AlÃ©m disso, nem sempre estÃ£o disponÃ­veis gratuitamente e podem exigir uma assinatura ou pagamento para uso. AlÃ©m disso, os usuÃ¡rios nÃ£o tÃªm controle sobre os dados usados para treinar o modelo, o que significa que devem confiar ao proprietÃ¡rio do modelo o compromisso com a privacidade dos dados e o uso responsÃ¡vel da IA. Exemplos de modelos proprietÃ¡rios populares incluem <a href="https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst">modelos da OpenAI</a>, <a href="https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst">Google Bard</a> ou <a href="https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst">Claude 2</a>.</p>
<h3 id="embeddings-versus-geracao-de-imagem-versus-geracao-de-texto-e-codigo">Embeddings versus GeraÃ§Ã£o de Imagem versus GeraÃ§Ã£o de Texto e CÃ³digo</h3>
<p>Os LLMs tambÃ©m podem ser categorizados com base na saÃ­da que geram.</p>
<p>Os <code>embeddings</code> sÃ£o um conjunto de modelos que podem converter texto em uma forma numÃ©rica, chamada <code>embedding</code>, que Ã© uma representaÃ§Ã£o numÃ©rica do texto de entrada. Os <code>embeddings</code> facilitam a compreensÃ£o das relaÃ§Ãµes entre palavras ou frases por mÃ¡quinas e podem ser usadas como entradas por outros modelos, como modelos de classificaÃ§Ã£o ou modelos de agrupamento que tÃªm um melhor desempenho com dados numÃ©ricos. Modelos de incorporaÃ§Ã£o sÃ£o frequentemente usados para aprendizado por transferÃªncia, onde um modelo Ã© construÃ­do para uma tarefa substituta para a qual hÃ¡ uma abundÃ¢ncia de dados, e em seguida, os pesos do modelo (<code>embeddings</code>) sÃ£o reutilizados para outras tarefas subsequentes. Um exemplo desta categoria Ã© <a href="https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst">Embeddings no OpenAI</a>.</p>
<p><img alt="Embedding" src="../../images/Embedding.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Modelos de geraÃ§Ã£o de imagem sÃ£o modelos que geram imagens. Esses modelos sÃ£o frequentemente usados para ediÃ§Ã£o de imagens, sÃ­ntese de imagens e traduÃ§Ã£o de imagens. Modelos de geraÃ§Ã£o de imagem sÃ£o frequentemente treinados em grandes conjuntos de dados de imagens, como <a href="https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst">LAION-5B</a>, e podem ser usados para gerar novas imagens ou editar imagens existentes com tÃ©cnicas de inpainting, super-resoluÃ§Ã£o e colorizaÃ§Ã£o. Exemplos incluem <a href="https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst">DALL-E-3</a> e <a href="https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst">modelos do Stable Diffusion</a>.</p>
<p><img alt="Image Generation" src="../../images/Image.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Modelos de geraÃ§Ã£o de texto e cÃ³digo sÃ£o modelos que geram texto ou cÃ³digo. Esses modelos sÃ£o frequentemente usados para resumir texto, traduzir e responder a perguntas. Modelos de geraÃ§Ã£o de texto sÃ£o frequentemente treinados em grandes conjuntos de dados de texto, como <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst">BookCorpus</a>, e podem ser usados para gerar novo texto ou responder a perguntas. Modelos de geraÃ§Ã£o de cÃ³digo, como <a href="https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst">CodeParrot</a>, sÃ£o frequentemente treinados em grandes conjuntos de dados de cÃ³digo, como o GitHub, e podem ser usados para gerar novo cÃ³digo ou corrigir bugs em cÃ³digo existente.</p>
<p><img alt="Text and code generation" src="../../images/Text.png?WT.mc_id=academic-105485-koreyst" /></p>
<h3 id="encoder-decoder-versus-decoder-only">Encoder-Decoder versus Decoder-only</h3>
<p>Para falar sobre os diferentes tipos de arquiteturas de Grandes Modelos de Linguagem (LLMs), vamos usar uma analogia.</p>
<p>Imagine que seu gerente te deu uma tarefa de escrever um questionÃ¡rio para os alunos. VocÃª tem dois colegas; um supervisiona a criaÃ§Ã£o do conteÃºdo e o outro supervisiona a revisÃ£o.</p>
<p>O criador de conteÃºdo Ã© como um modelo somente <code>Decoder</code>, ele pode olhar para o tÃ³pico e ver o que vocÃª jÃ¡ escreveu e entÃ£o ele pode escrever um curso com base nisso. Eles sÃ£o muito bons em escrever conteÃºdo envolvente e informativo, mas nÃ£o sÃ£o muito bons em entender o tÃ³pico e os objetivos de aprendizado. Alguns exemplos de modelos Decodificadores sÃ£o os modelos da famÃ­lia GPT, como o GPT-3.</p>
<p>O revisor Ã© como um modelo somente <code>Encoder</code>, eles olham para o curso escrito e as respostas, percebendo a relaÃ§Ã£o entre eles e entendendo o contexto, mas nÃ£o sÃ£o bons em gerar conteÃºdo. Um exemplo de modelo somente Codificador seria o BERT.</p>
<p>Imagine que tambÃ©m podemos ter alguÃ©m que possa criar e revisar o questionÃ¡rio, este Ã© um modelo <code>Encoder-Decoder</code>. Alguns exemplos seriam <code>BART</code> e <code>T5</code>.</p>
<h3 id="servico-versus-modelo">ServiÃ§o versus Modelo</h3>
<p>Agora, vamos falar sobre a diferenÃ§a entre um serviÃ§o e um modelo. Um serviÃ§o Ã© um produto oferecido por um Provedor de ServiÃ§os em Nuvem e Ã© frequentemente uma combinaÃ§Ã£o de modelos, dados e outros componentes. Um modelo Ã© o componente central de um serviÃ§o e Ã© frequentemente um modelo fundamental, como um LLM.</p>
<p>Os serviÃ§os sÃ£o frequentemente otimizados para uso em produÃ§Ã£o e muitas vezes sÃ£o mais fÃ¡ceis de usar do que os modelos, por meio de uma interface grÃ¡fica de usuÃ¡rio. No entanto, os serviÃ§os nem sempre estÃ£o disponÃ­veis gratuitamente e podem exigir uma assinatura ou pagamento para uso, em troca de aproveitar os recursos e equipamentos do proprietÃ¡rio do serviÃ§o, otimizando despesas e escalando facilmente. Um exemplo de serviÃ§o Ã© o <a href="https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst">ServiÃ§o do Azure OpenAI</a>, que oferece um plano de tarifas pay-as-you-go, o que significa que os usuÃ¡rios sÃ£o cobrados de acordo com o quanto usam o serviÃ§o. AlÃ©m disso, o serviÃ§o do Azure OpenAI oferece seguranÃ§a de nÃ­vel empresarial e um framework de IA responsÃ¡vel sobre as capacidades dos modelos.</p>
<p>Os modelos sÃ£o apenas as Redes Neurais, com parÃ¢metros, pesos e outros. Isso permite que as empresas os executem localmente. No entanto, elas precisariam comprar equipamentos, criar uma estrutura para escalar e adquirir uma licenÃ§a ou usar um modelo de cÃ³digo aberto. Um modelo como o <code>LLaMA</code> estÃ¡ disponÃ­vel para uso, exigindo poder computacional para executar o modelo.</p>
<h2 id="como-testar-e-iterar-com-diferentes-modelos-para-entender-o-desempenho-no-azure">Como testar e iterar com diferentes modelos para entender o desempenho no Azure</h2>
<p>Depois que nossa equipe explorou o cenÃ¡rio atual dos LLMs e identificou alguns bons candidatos para seus cenÃ¡rios, o prÃ³ximo passo Ã© testÃ¡-los em seus dados e carga de trabalho. Isso Ã© um processo iterativo, feito por meio de experimentos e mediÃ§Ãµes.
A maioria dos modelos mencionados nos parÃ¡grafos anteriores (modelos da OpenAI, modelos de cÃ³digo aberto como <code>Llama2</code> e <code>Hugging Face transformers</code>) estÃ¡ disponÃ­vel no <a href="https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-koreyst">Foundation Models</a> no <a href="https://ml.azure.com/?WT.mc_id=academic-105485-koreyst">Azure Machine Learning studio</a>.</p>
<p><a href="https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-koreyst">Azure Machine Learning</a> Ã© um serviÃ§o em nuvem projetado para Cientistas de Dados e Engenheiros de Machine Learning que gerenciam o ciclo completo de Aprendizado de MÃ¡quina (treinamento, teste, implantaÃ§Ã£o e gerenciamento de MLOps) em uma Ãºnica plataforma. O Machine Learning Studio oferece uma interface grÃ¡fica de usuÃ¡rio para este serviÃ§o e permite ao usuÃ¡rio:</p>
<ul>
<li>Encontrar o Foundation Model de interesse no catÃ¡logo, filtrando por tarefa, licenÃ§a ou nome. TambÃ©m Ã© possÃ­vel importar novos modelos que ainda nÃ£o estejam incluÃ­dos no catÃ¡logo.</li>
<li>Analisar o cartÃ£o do modelo, incluindo uma descriÃ§Ã£o detalhada e exemplos de cÃ³digo, e testÃ¡-lo com o widget de InferÃªncia de Amostra, fornecendo um prompt de amostra para testar o resultado.</li>
</ul>
<p><img alt="CartÃ£o do Modelo" src="../../images/Llama1.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Avaliar o desempenho do modelo com mÃ©tricas de avaliaÃ§Ã£o objetivas em uma carga de trabalho especÃ­fica e um conjunto de dados especÃ­fico fornecido como entrada.</li>
</ul>
<p><img alt="AvaliaÃ§Ã£o do Modelo" src="../../images/Llama2.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Ajustar o modelo com dados de treinamento personalizados para melhorar o desempenho do modelo em uma carga de trabalho especÃ­fica, aproveitando as capacidades de experimentaÃ§Ã£o e rastreamento do Aprendizado de MÃ¡quina do Azure.</li>
</ul>
<p><img alt="Ajuste do Modelo" src="../../images/Llama3.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Implante o modelo prÃ©-treinado original ou a versÃ£o ajustada a um ponto de extremidade remoto em tempo real ou por lote, para permitir que aplicativos o consumam.</li>
</ul>
<p><img alt="ImplantaÃ§Ã£o do Modelo" src="../../images/Llama4.png?WT.mc_id=academic-105485-koreyst" /></p>
<h2 id="melhorando-os-resultados-dos-llms">Melhorando os Resultados dos LLMs</h2>
<p>Exploramos com nossa equipe de startup diferentes tipos de Modelos de Linguagem de Grande Escala (LLMs) e uma Plataforma em Nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avaliÃ¡-los em dados de teste, melhorar o desempenho e implantÃ¡-los em pontos de extremidade de inferÃªncia.</p>
<p>Mas quando eles devem considerar o ajuste fino de um modelo em vez de usar um prÃ©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho especÃ­ficas?</p>
<p>Existem vÃ¡rias abordagens que uma empresa pode usar para obter os resultados desejados de um LLM, vocÃª pode selecionar diferentes tipos de modelos com diferentes graus de treinamento.</p>
<p>Implantar um LLM em produÃ§Ã£o, com diferentes nÃ­veis de complexidade, custo e qualidade. Aqui estÃ£o algumas abordagens diferentes:</p>
<ul>
<li>
<p><strong>Engenharia de prompts com contexto</strong>: a ideia Ã© fornecer contexto suficiente ao formular o prompt para garantir que vocÃª obtenha as respostas de que precisa.</p>
</li>
<li>
<p><strong>GeraÃ§Ã£o Aprimorada com RecuperaÃ§Ã£o, RAG</strong>: seus dados podem existir em um banco de dados ou ponto de extremidade da web, por exemplo. Para garantir que esses dados, ou um subconjunto deles, estejam incluÃ­dos no momento do prompt, vocÃª pode buscar os dados relevantes e tornÃ¡-los parte do prompt do usuÃ¡rio.</p>
</li>
<li>
<p><strong>Modelo ajustado fino</strong>: nesse caso, vocÃª treinou o modelo ainda mais com seus prÃ³prios dados, o que torna o modelo mais preciso e responsivo Ã s suas necessidades, mas pode ser custoso.</p>
</li>
</ul>
<p><img alt="ImplantaÃ§Ã£o de LLMs" src="../../images/Deploy.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Fonte da imagem: <a href="https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst">Quatro Maneiras de Empresas Implatarem LLMs | Blog Fiddler AI</a></p>
<h3 id="engenharia-de-prompts-com-contexto">Engenharia de Prompts com Contexto</h3>
<p>Os LLMs prÃ©-treinados funcionam muito bem em tarefas de linguagem natural generalizadas, mesmo quando chamados com um prompt curto, como uma frase a ser completada ou uma pergunta - o chamado "aprendizado de zero-shot".</p>
<p>No entanto, quanto mais o usuÃ¡rio puder estruturar sua consulta, com uma solicitaÃ§Ã£o detalhada e exemplos (o Contexto) mais precisa e prÃ³xima das expectativas do usuÃ¡rio serÃ¡ a resposta. Nesse caso, falamos de "aprendizado de um Ãºnico exemplo" se o prompt incluir apenas um exemplo e "aprendizado de alguns exemplos" se incluir vÃ¡rios exemplos.
A Engenharia de Prompts com contexto Ã© a abordagem mais econÃ´mica para comeÃ§ar.</p>
<h3 id="recuperacao-de-geracao-aumentada-rag">RecuperaÃ§Ã£o de GeraÃ§Ã£o Aumentada (RAG)</h3>
<p>Os LLMs tÃªm a limitaÃ§Ã£o de que sÃ³ podem usar os dados que foram usados durante seu treinamento para gerar uma resposta. Isso significa que eles nÃ£o sabem nada sobre os fatos que ocorreram apÃ³s seu processo de treinamento e nÃ£o podem acessar informaÃ§Ãµes nÃ£o pÃºblicas (como dados de uma empresa).
Isso pode ser superado por meio do <code>RAG</code>, uma tÃ©cnica que amplia o prompt com dados externos na forma de trechos de documentos, considerando limites de comprimento do prompt. Isso Ã© suportado por ferramentas de banco de dados vetoriais (como <a href="https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst">Azure Vector Search</a>) que recuperam trechos Ãºteis de vÃ¡rias fontes de dados predefinidas e os adicionam ao Contexto do prompt.</p>
<p>Essa tÃ©cnica Ã© muito Ãºtil quando uma empresa nÃ£o possui dados suficientes, tempo suficiente ou recursos para ajustar finamente um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho especÃ­fica e reduzir os riscos de alucinaÃ§Ãµes. Ou seja, mistificaÃ§Ã£o da realidade ou conteÃºdo prejudicial.</p>
<h3 id="modelo-ajustado-fino">Modelo Ajustado Fino</h3>
<p>O ajuste fino Ã© um processo que alavanca a aprendizagem por transferÃªncia para 'adaptar' o modelo a uma tarefa subsequente ou para resolver um problema especÃ­fico. Diferentemente do aprendizado de alguns exemplos e do RAG, ele resulta na geraÃ§Ã£o de um novo modelo, com pesos e vieses atualizados. Isso requer um conjunto de exemplos de treinamento consistindo de uma Ãºnica entrada (o prompt) e sua saÃ­da associada (a conclusÃ£o).
Essa seria a abordagem preferida se:</p>
<ul>
<li>
<p><strong>Usando modelos ajustados finamente</strong>: Uma empresa deseja usar modelos menos capazes ajustados finamente (como modelos de incorporaÃ§Ã£o) em vez de modelos de alto desempenho, resultando em uma soluÃ§Ã£o mais econÃ´mica e rÃ¡pida.</p>
</li>
<li>
<p><strong>Considerando a latÃªncia</strong>: A latÃªncia Ã© importante para um caso de uso especÃ­fico, portanto, nÃ£o Ã© possÃ­vel usar prompts muito longos ou o nÃºmero de exemplos que devem ser aprendidos a partir do modelo nÃ£o se encaixa no limite de comprimento do prompt.</p>
</li>
<li>
<p><strong>Mantendo-se atualizado</strong>: Uma empresa possui muitos dados de alta qualidade e rÃ³tulos de verdade fundamentais e os recursos necessÃ¡rios para manter esses dados atualizados ao longo do tempo.</p>
</li>
</ul>
<h3 id="modelo-treinado">Modelo Treinado</h3>
<p>Treinar um LLM a partir do zero Ã©, sem dÃºvida, a abordagem mais difÃ­cil e complexa de adotar, exigindo enormes quantidades de dados, recursos qualificados e poder computacional adequado. Essa opÃ§Ã£o deve ser considerada apenas em um cenÃ¡rio em que uma empresa possui um caso de uso especÃ­fico de domÃ­nio e uma grande quantidade de dados centrados no domÃ­nio.</p>
<h2 id="verificacao-de-conhecimento">VerificaÃ§Ã£o de Conhecimento</h2>
<p>Qual poderia ser uma boa abordagem para melhorar os resultados de completude do LLM?</p>
<ol>
<li>Engenharia de prompts com contexto</li>
<li>RAG</li>
<li>Modelo ajustado fino</li>
</ol>
<p>R: 3 Pois, se vocÃª tem o tempo, os recursos e dados de alta qualidade, o ajuste fino Ã© a melhor opÃ§Ã£o para se manter atualizado. No entanto, se vocÃª estÃ¡ procurando melhorar as coisas e estÃ¡ com pouco tempo, vale a pena considerar o RAG primeiro.</p>
<h2 id="desafio">ğŸš€ Desafio</h2>
<p>Saiba mais sobre como vocÃª pode <a href="https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst">usar o RAG</a> para o seu negÃ³cio.</p>
<h2 id="otimo-trabalho-continue-com-seu-aprendizado">Ã“timo Trabalho, Continue com Seu Aprendizado</h2>
<p>Deseja aprender mais sobre diferentes conceitos de IA Generativa? Acesse a <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">pÃ¡gina de aprendizado contÃ­nuo</a> para encontrar outros Ã³timos recursos sobre este tÃ³pico.</p>
<p>Vamos para a LiÃ§Ã£o 3, onde veremos como podemos <a href="../../../03-using-generative-ai-responsibly/translations/pt-br/?WT.mc_id=academic-105485-koreyst">Criar IA Generativa de forma ResponsÃ¡vel</a>!</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
