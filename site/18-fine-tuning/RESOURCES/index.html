<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Resources For Self-Guided Learning - GenAI for Beginner</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Resources For Self-Guided Learning";
        var mkdocs_page_input_path = "18-fine-tuning\\RESOURCES.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> GenAI for Beginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../00-course-setup/translations/cn/">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../09-building-image-applications/translations/cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">GenAI for Beginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Resources For Self-Guided Learning</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="resources-for-self-guided-learning">Resources For Self-Guided Learning</h1>
<p>The lesson was built using a number of core resources from OpenAI and Azure OpenAI as references for the terminology and tutorials. Here is a non-comprehensive list, for your own self-guided learning journeys.</p>
<h2 id="1-primary-resources">1. Primary Resources</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Title/Link</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst">Fine-tuning with OpenAI Models</a></td>
<td style="text-align: left;">Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt, saving you costs, improving response quality, and enabling lower-latency requests. <strong>Get an overview of fine-tuning from OpenAI.</strong></td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/azure/ai-services/openai/concepts/fine-tuning-considerations#what-is-fine-tuning-with-azure-openai?WT.mc_id=academic-105485-koreyst">What is Fine-Tuning with Azure OpenAI?</a></td>
<td style="text-align: left;">Understand <strong>what fine-tuning is (concept)</strong>, why you should look at it (motivating problem), what data to use (training) and measuring the quality</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&amp;pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst">Customize a model with fine-tuning</a></td>
<td style="text-align: left;">Azure OpenAI Service lets you tailor our models to your personal datasets using fine-tuning. Learn <strong>how to fine-tune (process)</strong> select models using Azure AI Studio, Python SDK or REST API.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning-recommend?WT.mc_id=academic-105485-koreyst">Recommendations for LLM fine-tuning</a></td>
<td style="text-align: left;">LLMs may not perform well on specific domains, tasks, or datasets, or may produce inaccurate or misleading outputs. <strong>When should you consider fine-tuning</strong> as a possible solution to this?</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython&amp;pivots=programming-language-studio#continuous-fine-tuning?WT.mc_id=academic-105485-koreyst">Continuous Fine Tuning</a></td>
<td style="text-align: left;">Continuous fine-tuning is the iterative process of selecting an already fine-tuned model as a base model and <strong>fine-tuning it further</strong> on new sets of training examples.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning-functions?WT.mc_id=academic-105485-koreyst">Fine-tuning and function calling</a></td>
<td style="text-align: left;">Fine-tuning your model <strong>with function calling examples</strong> can improve model output by getting more accurate and consistent outputs - with similarly-formatted responses &amp; cost-savings</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/azure/ai-services/openai/concepts/models#fine-tuning-models?WT.mc_id=academic-105485-koreyst">Fine-tuning Models: Azure OpenAI Guidance</a></td>
<td style="text-align: left;">Look up this table to understand <strong>what models can be fine-tuned</strong> in Azure OpenAI, and which regions these are available in. Look up their token limits and training data expiry dates if needed.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/shows/ai-show/to-fine-tune-or-not-fine-tune-that-is-the-question?WT.mc_id=academic-105485-koreyst">To Fine Tune or Not To Fine Tune? That is the Question</a></td>
<td style="text-align: left;">This 30-min <strong>Oct 2023</strong> episode of the AI Show discusses benefits, drawbacks and practical insights that help you make this decision.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://learn.microsoft.com/ai/playbook/technology-guidance/generative-ai/working-with-llms/fine-tuning?WT.mc_id=academic-105485-koreyst">Getting Started With LLM Fine-Tuning</a></td>
<td style="text-align: left;">This <strong>AI Playbook</strong> resource walks you through data requirements, formatting, hyperparameter fine-tuning and challenges/limitations you should know.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tutorial</strong>: <a href="https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Ccommand-line?WT.mc_id=academic-105485-koreyst">Azure OpenAI GPT3.5 Turbo Fine-Tuning</a></td>
<td style="text-align: left;">Learn to create a sample fine-tuning dataset, prepare for fine-tuning, create a fine-tuning job, and deploy the fine-tuned model on Azure.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tutorial</strong>: <a href="https://learn.microsoft.com/azure/ai-studio/how-to/fine-tune-model-llama?WT.mc_id=academic-105485-koreyst">Fine-tune a Llama 2 model in Azure AI Studio</a></td>
<td style="text-align: left;">Azure AI Studio lets you tailor large language models to your personal datasets <em>using a UI-based workflow suitable for low-code developers</em>. See this example.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tutorial</strong>:<a href="https://learn.microsoft.com/azure/databricks/machine-learning/train-model/huggingface/fine-tune-model?WT.mc_id=academic-105485-koreyst">Fine-tune Hugging Face models for a single GPU on Azure</a></td>
<td style="text-align: left;">This article describes how to fine-tune a Hugging Face model with the Hugging Face transformers library on a single GPU with Azure DataBricks + Hugging Face Trainer libraries</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Training:</strong> <a href="https://learn.microsoft.com/training/modules/finetune-foundation-model-with-azure-machine-learning/?WT.mc_id=academic-105485-koreyst">Fine-tune a foundation model with Azure Machine Learning</a></td>
<td style="text-align: left;">The model catalog in Azure Machine Learning offers many open source models you can fine-tune for your specific task. Try this module is <a href="https://learn.microsoft.com/training/paths/work-with-generative-models-azure-machine-learning/?WT.mc_id=academic-105485-koreyst">from the AzureML Generative AI Learning Path</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tutorial:</strong> <a href="https://docs.wandb.ai/guides/integrations/azure-openai-fine-tuning?WT.mc_id=academic-105485-koreyst">Azure OpenAI Fine-Tuning</a></td>
<td style="text-align: left;">Fine-tuning GPT-3.5 or GPT-4 models on Microsoft Azure using W&amp;B allows for detailed tracking and analysis of model performance. This guide extends the concepts from the OpenAI Fine-Tuning guide with specific steps and features for Azure OpenAI.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<h2 id="2-secondary-resources">2. Secondary Resources</h2>
<p>This section captures additional resources that are worth exploring, but that we did not have time to cover in this lesson. They may be covered in a future lesson, or as a secondary assignment option, at a later date. For now, use them to build your own expertise and knowledge around this topic.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Title/Link</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>OpenAI Cookbook</strong>: <a href="https://cookbook.openai.com/examples/chat_finetuning_data_prep?WT.mc_id=academic-105485-koreyst">Data preparation and analysis for chat model fine-tuning</a></td>
<td style="text-align: left;">This notebook serves as a tool to preprocess and analyze the chat dataset used for fine-tuning a chat model. It checks for format errors, provides basic statistics, and estimates token counts for fine-tuning costs. See: <a href="https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst">Fine-tuning method for gpt-3.5-turbo</a>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenAI Cookbook</strong>: <a href="https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant?WT.mc_id=academic-105485-koreyst">Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant</a></td>
<td style="text-align: left;">The aim of this notebook is to walk through a comprehensive example of how to fine-tune OpenAI models for Retrieval Augmented Generation (RAG). We will also be integrating Qdrant and Few-Shot Learning to boost model performance and reduce fabrications.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenAI Cookbook</strong>: <a href="https://cookbook.openai.com/examples/third_party/gpt_finetuning_with_wandb?WT.mc_id=academic-105485-koreyst">Fine-tuning GPT with Weights &amp; Biases</a></td>
<td style="text-align: left;">Weights &amp; Biases (W&amp;B) is the AI developer platform, with tools for training models, fine-tuning models, and leveraging foundation models. Read their <a href="https://docs.wandb.ai/guides/integrations/openai?WT.mc_id=academic-105485-koreyst">OpenAI Fine-Tuning</a> guide first, then try the Cookbook exercise.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Community Tutorial</strong> <a href="https://huggingface.co/blog/g-ronimo/phinetuning?WT.mc_id=academic-105485-koreyst">Phinetuning 2.0</a> - fine-tuning for Small Language Models</td>
<td style="text-align: left;">Meet <a href="https://www.microsoft.com/research/blog/phi-2-the-surprising-power-of-small-language-models/?WT.mc_id=academic-105485-koreyst">Phi-2</a>, Microsoft’s new small model, remarkably powerful yet compact. This tutorial will guide you through fine-tuning Phi-2, demonstrating how to build a unique dataset and fine-tune model using QLoRA.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Hugging Face Tutorial</strong> <a href="https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst">How to Fine-Tune LLMs in 2024 with Hugging Face</a></td>
<td style="text-align: left;">This blog post walks you thorugh how to fine-tune open LLMs using Hugging Face TRL, Transformers &amp; datasets in 2024. You define a use case, setup a dev environment, prepare a dataset, fine tune the model, test-evaluate it, then deploy it to production.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Hugging Face: <a href="https://github.com/huggingface/autotrain-advanced?WT.mc_id=academic-105485-koreyst">AutoTrain Advanced</a></strong></td>
<td style="text-align: left;">Brings faster and easier training and deployments of <a href="https://twitter.com/abhi1thakur/status/1755167674894557291?WT.mc_id=academic-105485-koreyst">state-of-the-art machine learning models</a>. Repo has Colab-friendly tutorials with YouTube video guidance, for fine-tuning. <strong>Reflects recent <a href="https://twitter.com/abhi1thakur/status/1750828141805777057?WT.mc_id=academic-105485-koreyst">local-first</a> update</strong> . Read the <a href="https://huggingface.co/autotrain?WT.mc_id=academic-105485-koreyst">AutoTrain documentation</a></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
