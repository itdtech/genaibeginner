<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>画像生成アプリケーションの構築 - genaibeginner</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u753b\u50cf\u751f\u6210\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u69cb\u7bc9";
        var mkdocs_page_input_path = "09-building-image-applications\\translations\\ja-jp\\README.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> genaibeginner
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../../../genaibeginner/00-course-setup/translations/cn/README.md">课程介绍和学习环境设置</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../01-introduction-to-genai/translations/cn/">第一章：生成式人工智能和 LLMs 介绍</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../02-exploring-and-comparing-different-llms/translations/cn/">第二章：探索和比较不同的 LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../03-using-generative-ai-responsibly/translations/cn/">第三章：负责任地使用生成式人工智能</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../04-prompt-engineering-fundamentals/translations/cn/">第四章：提示工程基础</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../05-advanced-prompts/translations/cn/">第五章：创建高级的提示工程技巧</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../06-text-generation-apps/translations/cn/">第六章：创建文本生成应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../07-building-chat-applications/translations/cn/">第七章：创建聊天应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../08-building-search-applications/translations/cn/">第八章：创建搜索应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cn/">第九章：创建图像应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../10-building-low-code-ai-applications/translations/cn/">第十章：创建低代码AI应用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../11-integrating-with-function-calling/translations/cn/">第十一章：集成函数调用</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../12-designing-ux-for-ai-applications/translations/cn/">第十二章：为人工智能应用程序设计用户体验</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../13-securing-ai-applications/translations/cn/">第十三章：保护AI应用程序</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../14-the-generative-ai-application-lifecycle/translations/cn/">第十四章：生成式AI应用生命周期</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../15-rag-and-vector-databases/translations/cn/">第十五章：检索增强生成和向量数据库</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../16-open-source-models/translations/tw/">第十六章：开源模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../17-ai-agents/translations/tw/">第十七章：AI Agent</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../18-fine-tuning/translations/tw/">第十八章：微调</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../19-slm/">第十九章：SLM模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../20-mistral/">第二十章：Mistral的模型</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../21-meta/">第二十一章：Meta的模型</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">genaibeginner</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">画像生成アプリケーションの構築</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="_1">画像生成アプリケーションの構築</h1>
<p><a href="https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst"><img alt="Building Image Generation Applications" src="../../images/09-lesson-banner.png?WT.mc_id=academic-105485-yoterada" /></a></p>
<p>LLM はテキスト生成だけでなく、テキストの説明から画像も生成できます。画像生成は、医療や建築、観光、ゲーム開発のように様々な業界において価値が高いとされています。この章では、最も人気のある 2 つの画像生成モデル、DALL-E と Midjourney について詳しく見ていきます。</p>
<h2 id="_2">はじめに</h2>
<p>このレッスンでは、下記の内容について説明します。</p>
<ul>
<li>画像生成の有用性</li>
<li>DALL-E と Midjourney の概要とその動作原理</li>
<li>画像生成アプリの作り方</li>
</ul>
<h2 id="_3">学習目標</h2>
<p>このレッスンを修了すると、下記を理解できます：</p>
<ul>
<li>画像生成アプリの作成</li>
<li>メタプロンプトを用いてアプリケーションの範囲を定義</li>
<li>DALL-E と Midjourney の活用方法</li>
</ul>
<h2 id="_4">画像生成アプリケーションを作る理由は何でしょう？</h2>
<p>画像生成アプリケーションは、生成 AI の能力を引き出す絶好の手段です。例えば、下記のような用途に利用できます：</p>
<ul>
<li>
<p><strong>画像編集と合成</strong>：画像編集や画像合成など、様々な用途の画像を生成できます。</p>
</li>
<li>
<p><strong>多種多様な業界への応用</strong>：医療技術、観光、ゲーム開発など、様々な業界の画像を生成できます。</p>
</li>
</ul>
<h2 id="edu4all">シナリオ ： Edu4All</h2>
<p>このレッスンでは、引き続きスタートアップの Edu4All で作業を進めていきます。生徒たちは評価用の画像を作成します。具体的にどのような画像を作るかは生徒たち次第ですが、自分たちの創作するおとぎ話のイラストを描いたり、物語の新しいキャラクターを作ったり、自分たちのアイデアや概念を視覚化する手助けをしてくれます。</p>
<p>例えば、Edu4All の生徒たちが授業で記念碑について学んでいる場合、下記のような画像を生成できます：</p>
<p><img alt="Edu4All startup, class on monuments, Eiffel Tower" src="../../images/startup.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>次のようなプロンプトを入力します。</p>
<blockquote>
<p>"早朝の日差しを浴びたエッフェル塔の前に座る犬"</p>
</blockquote>
<h2 id="dall-e-midjourney">DALL-E と Midjourney とは何でしょう？</h2>
<p><a href="https://openai.com/dall-e-2?WT.mc_id=academic-105485-yoterada">DALL-E</a> と <a href="https://www.midjourney.com/?WT.mc_id=academic-105485-yoterada">Midjourney</a> は、プロンプトを使って画像を生成できる、特に人気のある画像生成 AI モデルの 2 つです。</p>
<h3 id="dall-e">DALL-E</h3>
<p>まずは、テキストの説明から画像を生成する生成 AI モデル、DALL-E について見ていきましょう。</p>
<blockquote>
<p><a href="https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-yoterada">DALL-E は、CLIP と Diffused attention という 2 つのモデルを組み合わせたものです</a>.</p>
</blockquote>
<ul>
<li><strong>CLIP</strong> は、画像やテキストからデータの数値表現である埋め込みを生成するモデルです。</li>
<li><strong>Diffused attention</strong> は、埋め込みから画像を生成するモデルです。DALL-E は画像とテキストのデータセットで訓練され、テキストの説明から画像を生成できます。例えば、DALL-E を使って「帽子をかぶった猫」や「モヒカンヘアの犬」の画像を生成できます。</li>
</ul>
<h3 id="midjourney">Midjourney</h3>
<p>Midjourney も DALL-E と同様に、テキストプロンプトから画像を生成できます。Midjourney も同様に、「帽子をかぶった猫」や「モヒカンヘアの犬」などのプロンプトを使って画像を生成できます。</p>
<p><img alt="Image generated by Midjourney, mechanical pigeon" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-yoterada" />
<em>Image cred Wikipedia, image generated by Midjourney</em></p>
<h2 id="dall-e-midjourney_1">DALL-E と Midjourney はどのように動作するのでしょうか？</h2>
<p>まず、<a href="https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-yoterada">DALL-E</a> について説明します。DALL-E は、「<em>自己回帰型トランスフォーマー</em>」を用いたトランスフォーマー・アーキテクチャに基づく生成 AI モデルです。</p>
<p>「<em>自己回帰型トランスフォーマー</em>」は、AI モデルがテキストの説明から画像を生成する方法を定義します。このモデルは一度に 1 ピクセルずつ生成し、生成したピクセルを使って、次のピクセルを生成します。このプロセスは、画像が完成するまで、ニューラル・ネットワークの複数の層を通過していきます。</p>
<p>このプロセスを通じて、DALL-E は生成する画像の属性、オブジェクト、特性などを制御します。DALL-E 2 や 3 は生成された画像をより詳細に制御する能力を持っています。</p>
<h2 id="_5">初めての画像生成アプリケーションの構築</h2>
<p>画像生成アプリケーションを作るためには、下記のライブラリが必要です。</p>
<ul>
<li><strong>python-dotenv</strong>：強く推奨：このライブラリを利用し機密情報をコードから分離し「<em>.env</em>」ファイルに記述します</li>
<li><strong>openai</strong>：OpenAI API を利用するためのライブラリです</li>
<li><strong>pillow</strong>：Python で画像を扱うためのライブラリです</li>
<li>
<p><strong>requests</strong>：HTTP リクエストを作成するのに役立つライブラリです</p>
</li>
<li>
<p>下記の内容を記述した「<em>.env</em>」ファイルを作成します。</p>
</li>
</ul>
<p><code>text
   AZURE_OPENAI_ENDPOINT=&lt;your endpoint&gt;
   AZURE_OPENAI_API_KEY=&lt;your key&gt;</code></p>
<p>この情報は、Azure Portal の OpenAI を作成したリソースの「Keys and Endpoints」セクションで確認します。</p>
<ol>
<li>上記で示した必須ライブラリを「<em>requirements.txt</em>」という名前のファイルに記述します</li>
</ol>
<p><code>text
   python-dotenv
   openai
   pillow
   requests</code></p>
<ol>
<li>次に、仮想環境を作成し、ライブラリをインストールします</li>
</ol>
<p><code>bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt</code></p>
<p>Windows の場合は、下記のコマンドを実行して、仮想環境を作り利用できるようにします</p>
<p><code>bash
   python3 -m venv venv
   venv\Scripts\activate.bat</code></p>
<ol>
<li>「<em>app.py</em>」という名前のファイルに下記のコードを記述します</li>
</ol>
<p>```python
   import openai
   import os
   import requests
   from PIL import Image
   import dotenv</p>
<p># dotenvをインポート
   dotenv.load_dotenv()</p>
<p># 環境変数からエンドポイントとキーを取得
   openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
   openai.api_key = os.environ['AZURE_OPENAI_API_KEY']</p>
<p># API のバージョンを割り当て（DALL-E は現在、2023-06-01-preview API バージョンのみをサポートしています）
   openai.api_version = '2023-06-01-preview'
   openai.api_type = 'azure'</p>
<p>try:
       # 画像生成 API を使用して画像を作成
       generation_response = openai.Image.create(
           prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
           size='1024x1024',
           n=2,
           temperature=0,
       )
       # 画像を保存するディレクトリを設定
       image_dir = os.path.join(os.curdir, 'images')</p>
<pre><code>   # ディレクトリが存在しない場合は作成
   if not os.path.isdir(image_dir):
       os.mkdir(image_dir)

   # 画像ファイルへのパスを設定（ファイルタイプは png にします）
   image_path = os.path.join(image_dir, 'generated-image.png')

   # 生成した画像を取得
   image_url = generation_response["data"][0]["url"]  # レスポンスからイメージの URL を取得
   generated_image = requests.get(image_url).content  # イメージのダウンロード
   with open(image_path, "wb") as image_file:
       image_file.write(generated_image)

   # デフォルトの画像ビューアで画像を表示
   image = Image.open(image_path)
   image.show()
</code></pre>
<p># 例外をキャッチ
   except openai.InvalidRequestError as err:
       print(err)</p>
<p>```</p>
<p>上記のコードについて説明します。</p>
<ul>
<li>最初に、必要なライブラリをインポートします。これには、OpenAI ライブラリ、dotenv ライブラリ、requests ライブラリ、Pillow ライブラリが含まれます。</li>
</ul>
<p><code>python
  import openai
  import os
  import requests
  from PIL import Image
  import dotenv</code></p>
<ul>
<li>次に、「<em>.env</em>」ファイルから環境変数を読み込みます。</li>
</ul>
<p><code>python
  # dotenvをインポート
  dotenv.load_dotenv()</code></p>
<ul>
<li>その後、OpenAI API のエンドポイント、キー、バージョン、タイプを設定します。</li>
</ul>
<p>```python
  # 環境変数からエンドポイントとキーを取得
  openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
  openai.api_key = os.environ['AZURE_OPENAI_API_KEY']</p>
<p># バージョンと種類を設定、Azure 固有設定
  openai.api_version = '2023-06-01-preview'
  openai.api_type = 'azure'
  ```</p>
<ul>
<li>次に、画像を作成します。</li>
</ul>
<p><code>python
  # 画像生成 API を使用して画像を作成
  generation_response = openai.Image.create(
      prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
      size='1024x1024',
      n=2,
      temperature=0,
  )</code></p>
<p>上記のコードは、生成された画像の URL を含む JSON オブジェクトを返します。この URL を使って画像をダウンロードし、ファイルに保存できます。</p>
<ul>
<li>最後に、画像を開き、標準の画像ビューアを使って表示します。</li>
</ul>
<p><code>python
  image = Image.open(image_path)
  image.show()</code></p>
<h3 id="_6">画像生成の詳細</h3>
<p>画像を生成するコードをさらに詳しく見てみましょう。</p>
<pre><code class="language-python">generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2,
        temperature=0,
    )
</code></pre>
<ul>
<li><strong>prompt</strong>：画像を生成するためのテキスト・プロンプトです。この例では、「ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている」というプロンプトを使用しています。</li>
<li><strong>size</strong>：生成する画像のサイズを指定します。この例では、1024x1024 ピクセルの画像を生成しています。</li>
<li><strong>n</strong>：生成する画像の数です。この例では、2 つの画像を生成しています。</li>
<li><strong>temperature</strong>：生成 AI モデルの出力のランダム性を制御するパラメータです。温度は 0 から 1 の間の値で、0 は出力が決定的を意味し、1 は出力がランダムになります。デフォルト値は 0.7 です。</li>
</ul>
<p>次のセクションでは、画像生成でできる内容についてさらに詳しく説明します。</p>
<h2 id="_7">画像生成における追加機能</h2>
<p>ここまで、Python コードを実装して画像を生成する方法を見てきました。しかし、画像生成でできる処理は他にもあります。</p>
<p>下記のような処理も可能です。</p>
<ul>
<li><strong>画像編集を行う</strong>：既存の画像にマスクとプロンプトを提供し、画像を編集できます。例えば、画像の一部に、何かを新たに追加できます。たとえばウサギの画像を想像してみてください、ウサギに追加で帽子を被せれます。そのためには、画像、マスク（変更するエリアの部分を特定する）と、何をすべきかを示すテキストプロンプトを提供します。</li>
</ul>
<p><code>python
  response = openai.Image.create_edit(
    image=open("base_image.png", "rb"),
    mask=open("mask.png", "rb"),
    prompt="頭に帽子をかぶったウサギの画像",
    n=1,
    size="1024x1024"
  )
  image_url = response['data'][0]['url']</code></p>
<p>ベース画像にはウサギだけが含まれていますが、最終的な画像にはウサギの帽子が含まれています。</p>
<ul>
<li><strong>バリエーションを作成する</strong>：既存の画像を取得し、バリエーションを作成するように依頼します。バリエーションを作成するには、画像とテキストプロンプトを提供し、以下のようなコードを記述します。</li>
</ul>
<p><code>python
  response = openai.Image.create_variation(
    image=open("bunny-lollipop.png", "rb"),
    n=1,
    size="1024x1024"
  )
  image_url = response['data'][0]['url']</code></p>
<blockquote>
<p>ご注意：これは OpenAI でのみサポートされています。</p>
</blockquote>
<h2 id="_8">温度</h2>
<p>温度は、生成 AI モデルの出力のランダム性を制御するパラメータで、0 から 1 までの値を取ります。0 は出力が決定的で、1 は出力がランダムになります。デフォルト値は 0.7 になっています。</p>
<p>実際に確認するため、下記のプロンプトを二度実行して、温度がどのように作用するか確認してください。</p>
<blockquote>
<p>プロンプト : "ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている"</p>
</blockquote>
<p><img alt="Bunny on a horse holding a lollipop, version 1" src="../../images/v1-generated-image.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>同じプロンプトをもう一度実行し、前回とは異なる画像が出てくるかを確認します</p>
<p><img alt="Generated image of bunny on horse" src="../../images/v2-generated-image.png?WT.mc_id=academic-105485-yoterada" /></p>
<p>ご覧の通り、生成された画像は似ているように見えますが、同じではありません。ここで温度の値を 0.1 に変更して、その結果を見てみましょう。</p>
<pre><code class="language-python"> generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2
    )
</code></pre>
<h3 id="_9">温度を変更してみましょう</h3>
<p>結果をより決定的にしたい場合、生成した二つの画像から見て分かるように、最初の画像にはウサギが、二つ目の画像には馬が映っているので、２つの画像に大きな違いがあります。</p>
<p>そこで、コードを修正して温度を 0 に設定します。</p>
<pre><code class="language-python">generation_response = openai.Image.create(
        prompt='ウサギがキャンディを持って馬に乗り、霧のかかった牧場で水仙が育つ中を走っている',    # ここにプロンプトのテキストを入力
        size='1024x1024',
        n=2,
        temperature=0
    )
</code></pre>
<p>このコードを実行すると、次の二つの画像が得られます。</p>
<ul>
<li><img alt="Temperature 0, v1" src="../../images/v1-temp-generated-image.png?WT.mc_id=academic-105485-yoterada" /></li>
<li><img alt="Temperature 0 , v2" src="../../images/v2-temp-generated-image.png?WT.mc_id=academic-105485-yoterada" /></li>
</ul>
<p>これらの画像をご覧いただくと、２つの画像は明らかに似ています。</p>
<h2 id="_10">メタ・プロンプトを使ってアプリケーションの範囲を設定する方法</h2>
<p>上記のようにして、お客様に提供できる画像を生成できるようになっています。しかし、アプリケーションの範囲を設定する必要があります。</p>
<p>例えば、職場や学校にとって安全でない画像や、子供に適さない画像の生成は避けたいと思います。</p>
<p>これは<em>メタ・プロンプト</em>という手法を使って実現できます。メタ・プロンプトは、生成 AI モデルの出力を制御するために使用するテキスト・プロンプトです。例えば、メタ・プロンプトを使って出力を制御し、生成された画像が職場にとって安全か、子供にとって適しているかを確認できます。</p>
<h3 id="_11">それはどのように動作するのでしょうか？</h3>
<p>それでは、メタ・プロンプトはどのように動作するのでしょうか？</p>
<p>メタ・プロンプトは、生成 AI モデルの出力を制御するために使用するテキスト・プロンプトで、テキスト・プロンプトの前に配置し、モデルの出力を制御するために使用します。これはアプリケーションに組み込まれ、モデルの出力を制御します。プロンプト入力とメタ・プロンプト入力を一つのテキスト・プロンプトにまとめます。</p>
<p>メタ・プロンプトの一例を下記に示します。</p>
<pre><code class="language-text">あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は職場にとって安全で、子供にとって適している必要があります。

画像はカラーである必要があります。

画像は横長の形式である必要があります。

画像は16:9のアスペクト比である必要があります。

以下の入力から、職場に安全でない画像や子供にとって適さない画像は除外してください。

（入力）
</code></pre>
<p>さて、それではアプリでメタ・プロンプトをどのように使うか見てみましょう。</p>
<pre><code class="language-python">disallow_list = &quot;剣、暴力、血、ゴア、ヌード、性的コンテンツ、アダルト・コンテンツ、アダルト・テーマ、アダルト・ワード、アダルト・ユーモア、アダルト・ジョーク、アダルト・シチュエーション、アダルト&quot;

meta_prompt =f&quot;&quot;&quot;あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は職場の中で使用する際に安全で、子供に適している必要があります。

画像はカラーである必要があります。

画像は横長の形式である必要があります。

画像は16:9のアスペクト比である必要があります。

以下の入力から、職場に安全でない画像や子供にとって適さない画像は除外してください。
{disallow_list}
&quot;&quot;&quot;

prompt = f&quot;{meta_prompt}
ウサギがアメを持って馬に乗っている画像を作成してください&quot;

# TODO 画像生成のリクエストを追加
</code></pre>
<p>上記のプロンプトは、生成されるすべての画像がメタ・プロンプトを考慮しています。</p>
<h2 id="-">課題 - 学生の能力を引き出しましょう</h2>
<p>このレッスンの初めに Edu4All を紹介しました。今度は、学生が自分たちの評価のための画像を生成できるようにしましょう。</p>
<p>学生は、自分たちの評価用の画像を作成します。その画像には記念碑が含まれている必要がありますが、どの記念碑を選ぶかは学生に任せます。学生は、これらの記念碑をさまざまな状況に合わせるために、この課題では創造性の発揮が求められます。</p>
<h2 id="_12">解決策</h2>
<p>下記に一つの解決策案を示します：</p>
<pre><code class="language-python">import openai
import os
import requests
from PIL import Image
import dotenv

# dotenvをインポート
dotenv.load_dotenv()

# 環境変数からエンドポイントとキーを取得
openai.api_base = &quot;&lt;エンドポイントに置き換え&gt;&quot;
openai.api_key = &quot;&lt;API キーに置き換え&gt;&quot;

# APIバージョンを指定（DALL-Eは現在、2023-06-01-preview APIバージョンのみ対応）
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'

disallow_list = &quot;剣、暴力、血、ゴア、ヌード、性的コンテンツ、大人向けコンテンツ、大人向けテーマ、大人向け言語、大人向けユーモア、大人向けジョーク、大人向け状況、大人&quot;

meta_prompt = f&quot;&quot;&quot;あなたは子供向けの画像を作成するアシスタントデザイナーです。

画像は、職場において安全で、子供に適している必要があります。

画像はカラーである必要があります。

画像は横向きである必要があります。

画像は16:9のアスペクト比である必要があります。

以下の入力は、職場で安全でない、または子供に適していないので除外してください。
{disallow_list}&quot;&quot;&quot;

prompt = f&quot;&quot;&quot;{metaprompt}
フランスのパリにある凱旋門を夕暮れの光の中で描き、
小さな子供がテディベアを持って見つめている様子の
画像を生成してください。
&quot;&quot;&quot;&quot;

try:
    # 画像生成APIを使用して画像を作成
    generation_response = openai.Image.create(
        prompt=prompt,    # ここにプロンプト・テキストを入力
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # 保存する画像のディレクトリを設定
    image_dir = os.path.join(os.curdir, 'images')

    # ディレクトリが存在しない場合は作成
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # 画像のパスを初期化（ファイル形式は png）
    image_path = os.path.join(image_dir, 'generated-image.png')

    # 生成された画像を取得
    image_url = generation_response[&quot;data&quot;][0][&quot;url&quot;]  # レスポンスから画像URLを抽出
    generated_image = requests.get(image_url).content  # 画像をダウンロード
    with open(image_path, &quot;wb&quot;) as image_file:
        image_file.write(generated_image)

    # デフォルトの画像ビューアで画像を表示
    image = Image.open(image_path)
    image.show()

# 例外をキャッチ
except openai.InvalidRequestError as err:
    print(err)
</code></pre>
<h2 id="_13">お疲れ様でした!　学習を続ける</h2>
<p>このレッスン修了後、<a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-yoterada">生成 AI 学習コレクション</a> をチェックして、Generative AI の知識をレベルアップさせましょう。</p>
<p>次のレッスン 10 では、<a href="../../../10-building-low-code-ai-applications/translations/ja-jp/?WT.mc_id=academic-105485-yoterada">ローコード AI アプリケーションの構築</a>方法について学びます！</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
